1
00:00:00,000 --> 00:00:00,610

2
00:00:00,610 --> 00:00:01,830
JUSTIN UBERTI: Hi everyone.

3
00:00:01,830 --> 00:00:04,720
Thanks for coming to the
session on WebRTC for

4
00:00:04,720 --> 00:00:07,260
plugin-free realtime
communication.

5
00:00:07,260 --> 00:00:10,900
I'm Justin Uberti, tech lead
for WebRTC at Google.

6
00:00:10,900 --> 00:00:14,370
And with me today is-- hey,
has anyone seen Sam?

7
00:00:14,370 --> 00:00:18,650

8
00:00:18,650 --> 00:00:19,040
SAM DUTTON: Hey.

9
00:00:19,040 --> 00:00:21,630
JUSTIN UBERTI: Sam Dutton,
coming to you live from WebRTC

10
00:00:21,630 --> 00:00:25,230
on Chrome for Android.

11
00:00:25,230 --> 00:00:25,420
[APPLAUSE]

12
00:00:25,420 --> 00:00:26,670
SAM DUTTON: On a beautiful
Nexus 7.

13
00:00:26,670 --> 00:00:29,600

14
00:00:29,600 --> 00:00:33,070
We got this low-res to cope
with the Wi-Fi here.

15
00:00:33,070 --> 00:00:36,910
That seems to be working
pretty well.

16
00:00:36,910 --> 00:00:37,480
JUSTIN UBERTI: That was
quite an entrance.

17
00:00:37,480 --> 00:00:39,190
Why don't you come up here
and introduce yourself?

18
00:00:39,190 --> 00:00:40,080
SAM DUTTON: Yeah.

19
00:00:40,080 --> 00:00:40,650
Hey.

20
00:00:40,650 --> 00:00:41,470
I'm Sam Dutton.

21
00:00:41,470 --> 00:00:44,420
I'm a developer advocate
for Chrome.

22
00:00:44,420 --> 00:00:47,160

23
00:00:47,160 --> 00:00:48,640
JUSTIN UBERTI: So we're here to
talk to you today about the

24
00:00:48,640 --> 00:00:51,070
great things that WebRTC's been
working on and how you

25
00:00:51,070 --> 00:00:52,650
can use them.

26
00:00:52,650 --> 00:00:54,790
So what is WebRTC?

27
00:00:54,790 --> 00:00:57,600
In a nutshell, it's what we call
realtime communication--

28
00:00:57,600 --> 00:00:59,140
RTC--

29
00:00:59,140 --> 00:01:02,310
the ability to communicate
live with somebody or

30
00:01:02,310 --> 00:01:04,980
something as if you were right
there next to them.

31
00:01:04,980 --> 00:01:09,350
And this can mean audio,
video, or even just

32
00:01:09,350 --> 00:01:12,450
peer-to-peer data.

33
00:01:12,450 --> 00:01:15,740
And we think WebRTC
is really cool.

34
00:01:15,740 --> 00:01:18,020
But there's a lot of other
people who are really excited

35
00:01:18,020 --> 00:01:19,810
about WebRTC as well.

36
00:01:19,810 --> 00:01:23,880
And one of the reasons is that
WebRTC fills a critical gap in

37
00:01:23,880 --> 00:01:27,750
the web platform, where
previously, a native

38
00:01:27,750 --> 00:01:30,460
proprietary app like Skype could
do something the web

39
00:01:30,460 --> 00:01:31,940
just couldn't.

40
00:01:31,940 --> 00:01:34,620
But now we've turned that around
and changed that so we

41
00:01:34,620 --> 00:01:38,070
have a web of connected WebRTC
devices that can communicate

42
00:01:38,070 --> 00:01:43,060
in realtime just by loading
a web page.

43
00:01:43,060 --> 00:01:46,180
So here's what we're trying to
do with WebRTC, to build the

44
00:01:46,180 --> 00:01:50,510
key APIs for realtime
communication into the web, to

45
00:01:50,510 --> 00:01:54,030
make an amazing media stack in
Chrome so that developers can

46
00:01:54,030 --> 00:01:59,130
build great experiences, and
to use this network of

47
00:01:59,130 --> 00:02:01,670
connected WebRTC devices
to create a new

48
00:02:01,670 --> 00:02:04,200
communications ecosystem.

49
00:02:04,200 --> 00:02:07,380
And these kind of seem
like lofty goals.

50
00:02:07,380 --> 00:02:11,690
But take this quote from the
current CTO of the FCC who

51
00:02:11,690 --> 00:02:14,920
said he sees traditional
telephony fading away as voice

52
00:02:14,920 --> 00:02:16,558
just becomes another web app.

53
00:02:16,558 --> 00:02:19,490

54
00:02:19,490 --> 00:02:21,840
So we're trying to live
up to that promise.

55
00:02:21,840 --> 00:02:25,460
And right now, you can build a
single app with WebRTC that

56
00:02:25,460 --> 00:02:30,360
connects Chrome, Chrome for
Android, Firefox, and very

57
00:02:30,360 --> 00:02:32,280
soon, Opera.

58
00:02:32,280 --> 00:02:35,290
I'm especially excited to
announce the as of this week,

59
00:02:35,290 --> 00:02:38,590
Firefox 22 is going to beta,
which is the very first

60
00:02:38,590 --> 00:02:41,690
WebRTC-enabled version
of Firefox.

61
00:02:41,690 --> 00:02:47,570
So within a matter of weeks, we
will have over one billion

62
00:02:47,570 --> 00:02:51,111
users using a WebRTC-enabled
browser.

63
00:02:51,111 --> 00:02:56,770
[APPLAUSE]

64
00:02:56,770 --> 00:02:59,560
JUSTIN UBERTI: And I think that
just gives a good idea of

65
00:02:59,560 --> 00:03:02,010
the size of the opportunity
here.

66
00:03:02,010 --> 00:03:04,560
And we respect that number to
grow very significantly as

67
00:03:04,560 --> 00:03:07,720
both Chrome and Firefox get
increased adoption.

68
00:03:07,720 --> 00:03:10,770
For places where we don't have
WebRTC-enabled browsers, we're

69
00:03:10,770 --> 00:03:15,180
providing native, supported,
official tool kits on both

70
00:03:15,180 --> 00:03:20,460
Android, and very soon, iOS,
that can interoperate with

71
00:03:20,460 --> 00:03:21,620
WebRTC in the browser.

72
00:03:21,620 --> 00:03:27,610
[APPLAUSE]

73
00:03:27,610 --> 00:03:29,270
JUSTIN UBERTI: So here are
just a handful of the

74
00:03:29,270 --> 00:03:32,240
companies that see the
opportunity in WebRTC and are

75
00:03:32,240 --> 00:03:34,305
building their business
around it.

76
00:03:34,305 --> 00:03:37,700

77
00:03:37,700 --> 00:03:39,980
So that's the vision
for WebRTC.

78
00:03:39,980 --> 00:03:43,630
Now let's dig into the APIs.

79
00:03:43,630 --> 00:03:48,220
There are remain categories of
API that exist in WebRTC.

80
00:03:48,220 --> 00:03:52,410
First, getting access
to input devices--

81
00:03:52,410 --> 00:03:55,670
accessing the microphone,
accessing the webcam, getting

82
00:03:55,670 --> 00:03:58,350
a stream of media from
either of them.

83
00:03:58,350 --> 00:04:01,380
Secondly, being able to connect
to another WebRTC

84
00:04:01,380 --> 00:04:04,460
endpoint across the internet,
and to send this audio and

85
00:04:04,460 --> 00:04:06,180
video in realtime.

86
00:04:06,180 --> 00:04:09,000
And third, the ability to do
this not just for audio and

87
00:04:09,000 --> 00:04:12,190
video, but for arbitrary
application data.

88
00:04:12,190 --> 00:04:16,370
And we think this one is
especially interesting.

89
00:04:16,370 --> 00:04:17,700
So because there's
three categories,

90
00:04:17,700 --> 00:04:19,060
we have three objects.

91
00:04:19,060 --> 00:04:21,959
Three primary objects in WebRTC
to access this stuff.

92
00:04:21,959 --> 00:04:25,890
The first one, MediaStream, for
getting access to media,

93
00:04:25,890 --> 00:04:28,740
then RTCPeerConnection
and RTCDataChannel.

94
00:04:28,740 --> 00:04:32,270
And we'll get into each one
of these individually.

95
00:04:32,270 --> 00:04:35,130
Sam, why don't you tell
us about MediaStream?

96
00:04:35,130 --> 00:04:35,740
SAM DUTTON: Yeah, sure.

97
00:04:35,740 --> 00:04:41,300
So MediaStream represents a
single source of synchronized

98
00:04:41,300 --> 00:04:43,570
audio or video or both.

99
00:04:43,570 --> 00:04:49,420
Each MediaStream contains one
or more MediaStream tracks.

100
00:04:49,420 --> 00:04:53,900
For example, on your laptop,
you've got a webcam and a

101
00:04:53,900 --> 00:04:57,220
microphone providing video and
audio streams, and they're

102
00:04:57,220 --> 00:04:58,900
synchronized.

103
00:04:58,900 --> 00:05:04,160
We get access to these local
devices using the getUserMedia

104
00:05:04,160 --> 00:05:05,770
method of Navigator.

105
00:05:05,770 --> 00:05:09,430
So we just look at the code for
that, just highlight that.

106
00:05:09,430 --> 00:05:12,540
And you can see that
getUserMedia there, it takes

107
00:05:12,540 --> 00:05:14,950
three parameters, three
arguments there.

108
00:05:14,950 --> 00:05:17,550
And the first one, if we look
at the constraints argument

109
00:05:17,550 --> 00:05:21,160
I've got, you can see I'm just
specifying I want video.

110
00:05:21,160 --> 00:05:21,980
That's all I'm saying.

111
00:05:21,980 --> 00:05:24,440
Just give me video
and nothing else.

112
00:05:24,440 --> 00:05:27,410
And then in the success
callback, we're setting the

113
00:05:27,410 --> 00:05:33,460
source of a video using the
stream that's returned by

114
00:05:33,460 --> 00:05:34,910
getUserMedia.

115
00:05:34,910 --> 00:05:38,770
Let's see that in action, really
simple example here.

116
00:05:38,770 --> 00:05:43,730
And you can see when we fire
the getUserMedia method, we

117
00:05:43,730 --> 00:05:47,110
get the allow permissions
bar at the top there.

118
00:05:47,110 --> 00:05:50,640
Now, this means that users have
to explicitly opt in to

119
00:05:50,640 --> 00:05:52,940
allowing access to their
microphone and camera.

120
00:05:52,940 --> 00:05:53,760
And yeah, there we have it.

121
00:05:53,760 --> 00:05:56,010
Using that code,
we've got video

122
00:05:56,010 --> 00:05:57,570
displayed in a video element.

123
00:05:57,570 --> 00:05:58,830
Great.

124
00:05:58,830 --> 00:06:02,940
What really excites me about
these APIs is when they come

125
00:06:02,940 --> 00:06:06,250
up against each other,
like in this example.

126
00:06:06,250 --> 00:06:09,600
What's happening is, that we've
got getUserMedia being

127
00:06:09,600 --> 00:06:13,160
piped into a canvas element,
and then the canvas element

128
00:06:13,160 --> 00:06:16,880
being analyzed, and then
producing ASCII, just like

129
00:06:16,880 --> 00:06:19,873
that, which could make a
good codec, I think.

130
00:06:19,873 --> 00:06:20,620
JUSTIN UBERTI: It would
be a good codec.

131
00:06:20,620 --> 00:06:22,210
You can press it using
just gzip.

132
00:06:22,210 --> 00:06:26,820
SAM DUTTON: Yeah, smaller font
sizes, high resolution.

133
00:06:26,820 --> 00:06:29,930
Also, another example of
this from Facekat.

134
00:06:29,930 --> 00:06:33,520
Now what's happening here is
that it's using the head

135
00:06:33,520 --> 00:06:38,600
tracker JavaScript library to
track the position of my head.

136
00:06:38,600 --> 00:06:42,240
And when I move around, you can
see I'm moving through the

137
00:06:42,240 --> 00:06:49,340
game and trying to stay alive,
which is quite difficult.

138
00:06:49,340 --> 00:06:50,760
God, this is painful.

139
00:06:50,760 --> 00:06:52,490
Anyway--

140
00:06:52,490 --> 00:06:54,220
whoa.

141
00:06:54,220 --> 00:06:58,090
OK, I think I've flipped
into hyperspace there.

142
00:06:58,090 --> 00:07:00,740
And an old favorite, you've may
well have seen a webcam

143
00:07:00,740 --> 00:07:03,670
toy which gives us access to the
camera, kind of photobooth

144
00:07:03,670 --> 00:07:10,240
app, uses WebGL to create a
bunch of slightly psychedelic

145
00:07:10,240 --> 00:07:11,300
effects there.

146
00:07:11,300 --> 00:07:13,560
I quite this old movie
one, so I'll take

147
00:07:13,560 --> 00:07:18,870
that and get a snapshot.

148
00:07:18,870 --> 00:07:21,400
And I can share that with my
friends, so beautiful work

149
00:07:21,400 --> 00:07:23,790
from Paul Neave there.

150
00:07:23,790 --> 00:07:27,450
Now you might remember I said
that we can use the

151
00:07:27,450 --> 00:07:28,370
constraints object.

152
00:07:28,370 --> 00:07:30,990
The simple example there was
just saying, use the video,

153
00:07:30,990 --> 00:07:31,780
nothing else.

154
00:07:31,780 --> 00:07:33,650
Well, we can do more interesting
things with

155
00:07:33,650 --> 00:07:35,670
constraints than that.

156
00:07:35,670 --> 00:07:38,600
We can do stuff like specify
the resolution or the frame

157
00:07:38,600 --> 00:07:40,670
rate, a whole stack of
things that we want

158
00:07:40,670 --> 00:07:42,630
from our local devices.

159
00:07:42,630 --> 00:07:46,130
A little example from that,
if we go over here.

160
00:07:46,130 --> 00:07:48,630
Now, let's look at the
code, actually.

161
00:07:48,630 --> 00:07:51,370
If we go to the dev tools there,
you can see that I've

162
00:07:51,370 --> 00:07:55,860
got three different constraints
objects, one for

163
00:07:55,860 --> 00:07:56,860
each resolution.

164
00:07:56,860 --> 00:08:01,280
So when I press the buttons,
I use the QVGA constraints,

165
00:08:01,280 --> 00:08:04,730
getUserMedia, and then with the
VGA one, I'm getting high

166
00:08:04,730 --> 00:08:05,610
resolution.

167
00:08:05,610 --> 00:08:12,500
And for HD, I'm getting
the full 1280 by 720.

168
00:08:12,500 --> 00:08:17,330
We can also use getUserMedia
now for input from our

169
00:08:17,330 --> 00:08:18,230
microphone.

170
00:08:18,230 --> 00:08:21,540
In other words, we can use
getUserMedia to provide a

171
00:08:21,540 --> 00:08:23,790
source node for web audio.

172
00:08:23,790 --> 00:08:26,380
And there's a huge amount of
interesting stuff we can do

173
00:08:26,380 --> 00:08:30,160
with that processing audio using
web audio, from the mic

174
00:08:30,160 --> 00:08:30,680
or wherever.

175
00:08:30,680 --> 00:08:33,496
A little example
of that here--

176
00:08:33,496 --> 00:08:36,105
I'll just allowed access to the
mic, and you can see, I'm

177
00:08:36,105 --> 00:08:38,210
getting a nice little
visualization there in the

178
00:08:38,210 --> 00:08:39,530
canvas element.

179
00:08:39,530 --> 00:08:41,360
And I can start to
record this, blah

180
00:08:41,360 --> 00:08:42,770
blah blah blah blah--

181
00:08:42,770 --> 00:08:43,075
[AUDIO PLAYBACK]

182
00:08:43,075 --> 00:08:45,055
-To record this, blah blah
blah blah blah--

183
00:08:45,055 --> 00:08:45,750
[END AUDIO PLAYBACK]

184
00:08:45,750 --> 00:08:49,230
SAM DUTTON: And yeah, you can
see that's used recorder.js to

185
00:08:49,230 --> 00:08:50,480
save that locally to disk.

186
00:08:50,480 --> 00:08:53,090

187
00:08:53,090 --> 00:08:55,740
GetUserMedia also now-- this is
kind of experimental, but

188
00:08:55,740 --> 00:08:59,470
we can use getUserMedia to get
a screen capture, in other

189
00:08:59,470 --> 00:09:03,990
words data coming directly from
what we see on screen,

190
00:09:03,990 --> 00:09:08,190
not from the audio video from
the mic and the camera.

191
00:09:08,190 --> 00:09:09,820
Probably the simplest if I show
you an example of this,

192
00:09:09,820 --> 00:09:12,950
so yeah, a little application
here.

193
00:09:12,950 --> 00:09:19,140
And when I click to make the
call, allow, and you can see

194
00:09:19,140 --> 00:09:23,610
there that I get this kind of
crazy hall of mirrors effect,

195
00:09:23,610 --> 00:09:26,790
because I'm capturing the screen
that I'm capturing, and

196
00:09:26,790 --> 00:09:28,980
so on and so on.

197
00:09:28,980 --> 00:09:30,900
Now that's quite nice.

198
00:09:30,900 --> 00:09:34,700
But it would be really useful
if we could take that screen

199
00:09:34,700 --> 00:09:39,980
capture and then transmit that
to another computer.

200
00:09:39,980 --> 00:09:44,450
And for that, we have
RTCPeerConnection.

201
00:09:44,450 --> 00:09:45,360
JUSTIN UBERTI: Thanks, Sam.

202
00:09:45,360 --> 00:09:48,880
So as the name implies,
RTCPeerConnection is all about

203
00:09:48,880 --> 00:09:53,210
making a connection to another
peer and over this peer

204
00:09:53,210 --> 00:09:54,770
connection, we can actually
then go and

205
00:09:54,770 --> 00:09:56,370
send audio and video.

206
00:09:56,370 --> 00:09:59,360
And the way we do this is we
take the media streams that

207
00:09:59,360 --> 00:10:02,380
we've got from getUserMedia, and
we plug them into the peer

208
00:10:02,380 --> 00:10:05,910
connection, and send them
off to the other side.

209
00:10:05,910 --> 00:10:08,100
When the other side receives
them, they'll pop out as a new

210
00:10:08,100 --> 00:10:10,470
media stream on their
peer connection.

211
00:10:10,470 --> 00:10:12,290
And they can then plug that
into a video element to

212
00:10:12,290 --> 00:10:13,920
display on the page.

213
00:10:13,920 --> 00:10:16,480
And so both sides of a peer
connection, they both get

214
00:10:16,480 --> 00:10:19,230
streams from getUserMedia, they
plug them in, and then

215
00:10:19,230 --> 00:10:22,140
those media streams pop out
magically encoded and decoded

216
00:10:22,140 --> 00:10:23,890
on the other side.

217
00:10:23,890 --> 00:10:26,570
Now under the hood,
peer connection is

218
00:10:26,570 --> 00:10:28,510
doing a ton of stuff--

219
00:10:28,510 --> 00:10:31,840
signal processing to remove
noise from audio and video;

220
00:10:31,840 --> 00:10:34,070
codec selection and compression
and decompression

221
00:10:34,070 --> 00:10:36,790
of the actual audio and video;
finding the actual

222
00:10:36,790 --> 00:10:39,590
peer-to-peer route through
firewalls, through NATs,

223
00:10:39,590 --> 00:10:43,040
through relays; encrypting the
data so that a user's data is

224
00:10:43,040 --> 00:10:46,070
fully protected at all times;
and then actually managing the

225
00:10:46,070 --> 00:10:49,100
bandwidth so that if you have
two megabits, we use it.

226
00:10:49,100 --> 00:10:51,880
If you have 200 kilobits,
that's all we use.

227
00:10:51,880 --> 00:10:55,680
But we do everything we can hide
this complexity from that

228
00:10:55,680 --> 00:10:57,840
web developer.

229
00:10:57,840 --> 00:11:01,930
And so the main thing is that
you get your media streams,

230
00:11:01,930 --> 00:11:03,660
you plug them in via
Adstream to peer

231
00:11:03,660 --> 00:11:05,840
connection, and off you go.

232
00:11:05,840 --> 00:11:08,850
And here's a little
example of this.

233
00:11:08,850 --> 00:11:12,210
SAM DUTTON: Yeah, so you can see
here that we've created a

234
00:11:12,210 --> 00:11:14,580
new RTCPeerConnection.

235
00:11:14,580 --> 00:11:18,360
And when the stream is received,
the callback for

236
00:11:18,360 --> 00:11:22,710
that in gotRemoteStream there
attaches the media we're

237
00:11:22,710 --> 00:11:26,120
getting from a video element
to the stream.

238
00:11:26,120 --> 00:11:29,390
Now, at the same time, we're
also creating what's called an

239
00:11:29,390 --> 00:11:32,930
offer, giving information about
media, and we're setting

240
00:11:32,930 --> 00:11:36,150
that as the local description,
and then sending that to the

241
00:11:36,150 --> 00:11:38,820
callee, so that they can set
the remote description.

242
00:11:38,820 --> 00:11:42,590
You can see that in the
gotAnswer function there.

243
00:11:42,590 --> 00:11:46,280
Let's have a little look at
RTCPeerConnection on one page,

244
00:11:46,280 --> 00:11:48,850
a very simple example here.

245
00:11:48,850 --> 00:11:54,730
So what we've got here
is getUserMedia here,

246
00:11:54,730 --> 00:11:55,665
just start that up.

247
00:11:55,665 --> 00:11:59,090
So it's getting video from the
local camera here, displaying

248
00:11:59,090 --> 00:12:00,210
it on the left there.

249
00:12:00,210 --> 00:12:05,320
Now when I press call, it's
using RTCPeerConnection to

250
00:12:05,320 --> 00:12:08,660
communicate that video
to the other--

251
00:12:08,660 --> 00:12:10,880
yeah, the other video element
on the page there.

252
00:12:10,880 --> 00:12:13,370
This is a great place to start
to get your head around

253
00:12:13,370 --> 00:12:14,770
RTCPeerConnection.

254
00:12:14,770 --> 00:12:18,940
And if we look in the code
there, you can see that it's

255
00:12:18,940 --> 00:12:19,710
really simple.

256
00:12:19,710 --> 00:12:22,420
There's not a lot of code there
to do that, to transmit

257
00:12:22,420 --> 00:12:24,820
video from one peer
to another.

258
00:12:24,820 --> 00:12:27,370

259
00:12:27,370 --> 00:12:28,440
JUSTIN UBERTI: So that's
really cool stuff.

260
00:12:28,440 --> 00:12:31,310
A full video chat client in a
single web page, and just

261
00:12:31,310 --> 00:12:33,210
about 15 lines of JavaScript.

262
00:12:33,210 --> 00:12:35,250
And we talked a bit quickly
through the whole thing around

263
00:12:35,250 --> 00:12:37,350
how we set up the parameter of
the call, the offers and

264
00:12:37,350 --> 00:12:39,840
answers, but I'll come
back to that later.

265
00:12:39,840 --> 00:12:42,820
The next thing I want to talk
about is RTCDataChannel.

266
00:12:42,820 --> 00:12:45,540
And this says, if we have a peer
connection which already

267
00:12:45,540 --> 00:12:47,940
creates our peer-to-peer link
for us, can we send arbitrary

268
00:12:47,940 --> 00:12:49,520
application data over it?

269
00:12:49,520 --> 00:12:52,140
And this is the mechanism
that we use to do so.

270
00:12:52,140 --> 00:12:55,270
Now one example where we would
do this would be in a game.

271
00:12:55,270 --> 00:12:56,160
Like, take this game.

272
00:12:56,160 --> 00:12:58,500
I think it's called Jank
Wars or something.

273
00:12:58,500 --> 00:13:01,350
And we have all these ships
floating around onscreen.

274
00:13:01,350 --> 00:13:03,810
Now, when a ship moves, we
want to make sure that's

275
00:13:03,810 --> 00:13:06,680
communicated to the other player
as quickly as possible.

276
00:13:06,680 --> 00:13:09,650
And so we have this little JSON
object that contains the

277
00:13:09,650 --> 00:13:13,720
parameters and the position and
the velocity of the ships.

278
00:13:13,720 --> 00:13:16,880
And we can just take that object
and stuff it into the

279
00:13:16,880 --> 00:13:19,685
send method, and it will shoot
it across the other side where

280
00:13:19,685 --> 00:13:21,630
it pops out as onMessage.

281
00:13:21,630 --> 00:13:23,490
And the other side can
do the same thing.

282
00:13:23,490 --> 00:13:26,430
It can call send on its data
channel, and it works pretty

283
00:13:26,430 --> 00:13:28,860
much just like a WebSocket.

284
00:13:28,860 --> 00:13:30,140
That's not an accident.

285
00:13:30,140 --> 00:13:32,410
And we tried to design it that
way, so that people familiar

286
00:13:32,410 --> 00:13:35,490
with using WebSockets could
also use a similar API for

287
00:13:35,490 --> 00:13:37,020
RTCDataChannel.

288
00:13:37,020 --> 00:13:39,770
And the benefit is that here,
we have a peer-to-peer

289
00:13:39,770 --> 00:13:43,050
connection with the lowest
possible latency for doing

290
00:13:43,050 --> 00:13:44,540
this communication.

291
00:13:44,540 --> 00:13:46,460
In addition, RTCDataChannel.

292
00:13:46,460 --> 00:13:49,370
can be either unreliable
or reliable.

293
00:13:49,370 --> 00:13:53,140
And we can think about this kind
of like UDP versus TCP.

294
00:13:53,140 --> 00:13:55,200
If you're doing a game, it's
more important that your

295
00:13:55,200 --> 00:13:56,930
packets get there quickly
than they're

296
00:13:56,930 --> 00:13:58,310
guaranteed to get there.

297
00:13:58,310 --> 00:14:01,500
Whereas if you're doing a file
transfer, the files are only

298
00:14:01,500 --> 00:14:03,920
any good if the entire
file is delivered.

299
00:14:03,920 --> 00:14:07,230
So you can choose this as the
app developer, which mode you

300
00:14:07,230 --> 00:14:10,140
want to use, either unreliable
or reliable.

301
00:14:10,140 --> 00:14:13,130
And lastly, everything
is fully secure.

302
00:14:13,130 --> 00:14:16,580
We use standard DTLS encryption
to make sure that

303
00:14:16,580 --> 00:14:18,850
the packages you send across
the data channel are fully

304
00:14:18,850 --> 00:14:21,620
encrypted on their way
to the destination.

305
00:14:21,620 --> 00:14:24,240
And you can do this either with
audio and video, or if

306
00:14:24,240 --> 00:14:26,570
you want to make a peer
connection for just data, you

307
00:14:26,570 --> 00:14:29,120
can do that as well.

308
00:14:29,120 --> 00:14:31,500
So Sam's going to show us
how this actually works.

309
00:14:31,500 --> 00:14:33,800
SAM DUTTON: Yeah, so again,
another really simple example.

310
00:14:33,800 --> 00:14:38,330
We're creating a peer connection
here, and once the

311
00:14:38,330 --> 00:14:41,550
data channel is received, in
the callback to that, we're

312
00:14:41,550 --> 00:14:44,060
setting the receive
channel using the

313
00:14:44,060 --> 00:14:46,950
event.channel object.

314
00:14:46,950 --> 00:14:49,890
Now, when the receive channel
gets a message, kind of like

315
00:14:49,890 --> 00:14:55,670
WebSocket really, we're just
putting some text in a local

316
00:14:55,670 --> 00:14:57,910
div there, using event.data.

317
00:14:57,910 --> 00:15:00,360
Now, the send channel
was created with

318
00:15:00,360 --> 00:15:01,770
createDataChannel.

319
00:15:01,770 --> 00:15:03,770
And then we got a send button.

320
00:15:03,770 --> 00:15:07,280
When that's clicked, we get the
data from a text area, and

321
00:15:07,280 --> 00:15:10,580
we use the send channel to send
that to the other peer.

322
00:15:10,580 --> 00:15:12,800
Again, let's see
this in action.

323
00:15:12,800 --> 00:15:16,760
This is, again, a good place to
start-- one page demo, with

324
00:15:16,760 --> 00:15:19,245
all the code for RTCDataChannel,
so type in

325
00:15:19,245 --> 00:15:23,320
some text, and we hit send, and
it's transmitting it to

326
00:15:23,320 --> 00:15:25,850
the other text area.

327
00:15:25,850 --> 00:15:28,160
A great place to start
if you're looking at

328
00:15:28,160 --> 00:15:30,280
RTCDataChannel.

329
00:15:30,280 --> 00:15:32,750
Something a little more
useful here, a

330
00:15:32,750 --> 00:15:35,850
great app from Sharefest.

331
00:15:35,850 --> 00:15:39,170
Now, Sharefest is using
RTCDataChannel.

332
00:15:39,170 --> 00:15:40,790
to enable us to do
file sharing.

333
00:15:40,790 --> 00:15:43,600
I think I'm going to select a
nice photo here I've got of

334
00:15:43,600 --> 00:15:45,130
some cherries.

335
00:15:45,130 --> 00:15:47,130
And it's popeye, is the URL.

336
00:15:47,130 --> 00:15:51,400
And now Justin is going to try
and get that up on screen on

337
00:15:51,400 --> 00:15:54,000
his side, just to check that
that's gone through.

338
00:15:54,000 --> 00:15:57,470
So like I say, this is doing
file sharing using

339
00:15:57,470 --> 00:16:00,200
RTCDataChannel, and there's
a huge amount

340
00:16:00,200 --> 00:16:00,680
of potential there.

341
00:16:00,680 --> 00:16:00,930
There we go.

342
00:16:00,930 --> 00:16:01,960
Those are the cherries.

343
00:16:01,960 --> 00:16:03,400
JUSTIN UBERTI: I
love cherries.

344
00:16:03,400 --> 00:16:04,750
SAM DUTTON: These are beautiful
Mountain View

345
00:16:04,750 --> 00:16:05,370
cherries, actually.

346
00:16:05,370 --> 00:16:07,485
They were really, really nice.

347
00:16:07,485 --> 00:16:09,450
JUSTIN UBERTI: All this data
is being sent peer-to-peer,

348
00:16:09,450 --> 00:16:12,480
and anybody else who connects to
the same URL will download

349
00:16:12,480 --> 00:16:15,140
that data peer-to-peer
from Sam's machine.

350
00:16:15,140 --> 00:16:18,270
And so none of this has to
touch Sharefest servers.

351
00:16:18,270 --> 00:16:19,850
And I think that's pretty
interesting if you think about

352
00:16:19,850 --> 00:16:22,470
things like file transfer and
bulk video distribution.

353
00:16:22,470 --> 00:16:31,390

354
00:16:31,390 --> 00:16:34,130
OK, so we talked a lot about
how we can do really clever

355
00:16:34,130 --> 00:16:38,080
peer-to-peer stuff with
RTCPeerConnection.

356
00:16:38,080 --> 00:16:40,090
But it turns out we need servers
to kind of get the

357
00:16:40,090 --> 00:16:41,960
process kicked off.

358
00:16:41,960 --> 00:16:44,790
And the first part of it is
actually making sure that both

359
00:16:44,790 --> 00:16:48,220
sides can agree to actually
conduct the session.

360
00:16:48,220 --> 00:16:51,800
And this is the process that
we call signaling.

361
00:16:51,800 --> 00:16:54,950
The signaling in WebRTC is
abstract, which means that

362
00:16:54,950 --> 00:16:56,660
there's no fully-defined
protocol on

363
00:16:56,660 --> 00:16:58,650
exactly how you do it.

364
00:16:58,650 --> 00:17:01,530
The key part is that you just
have to exchange session

365
00:17:01,530 --> 00:17:02,500
description objects.

366
00:17:02,500 --> 00:17:05,869
And if you think about this kind
of like a telephone call,

367
00:17:05,869 --> 00:17:07,990
when you make a call to someone,
the telephone network

368
00:17:07,990 --> 00:17:10,420
sends a message to the person
you're calling, telling them

369
00:17:10,420 --> 00:17:13,260
there's an incoming call and
the phone should ring.

370
00:17:13,260 --> 00:17:16,220
Then, when they answer the call,
they send a message back

371
00:17:16,220 --> 00:17:19,099
that says, the call
is now active.

372
00:17:19,099 --> 00:17:21,980
Now, these messages also contain
parameters around what

373
00:17:21,980 --> 00:17:24,880
media format to use, where the
person is on the network, and

374
00:17:24,880 --> 00:17:26,760
the same is true for WebRTC.

375
00:17:26,760 --> 00:17:28,580
And these things, these session
description objects,

376
00:17:28,580 --> 00:17:33,250
contain parameters like, what
codecs to use, what security

377
00:17:33,250 --> 00:17:35,750
keys to use, the network
information for setting up the

378
00:17:35,750 --> 00:17:37,360
peer-to-peer route.

379
00:17:37,360 --> 00:17:39,350
And the only important thing is
that you just send it from

380
00:17:39,350 --> 00:17:41,800
your side to the other
side, and vice versa.

381
00:17:41,800 --> 00:17:44,140
You can use any mechanism
you want--

382
00:17:44,140 --> 00:17:47,610
WebSockets, Google Cloud
Messaging, XHR.

383
00:17:47,610 --> 00:17:50,840
You can use any protocol, even
just send it as JSON, or you

384
00:17:50,840 --> 00:17:54,250
can use a standard protocols
like SIP or XMPP.

385
00:17:54,250 --> 00:17:57,490
Here's a picture of how
this all works.

386
00:17:57,490 --> 00:18:00,490
The app gets a session
description from the browser

387
00:18:00,490 --> 00:18:03,370
and sends it across through the
cloud to the other side.

388
00:18:03,370 --> 00:18:05,470
Once it gets the message back
from the other side with the

389
00:18:05,470 --> 00:18:08,870
other side's session
description, and both sessions

390
00:18:08,870 --> 00:18:12,380
consider passed down to WebRTC
in the browser, WebRTC can

391
00:18:12,380 --> 00:18:15,170
then set up and conduct the
media link peer-to-peer.

392
00:18:15,170 --> 00:18:17,950

393
00:18:17,950 --> 00:18:21,250
So we do a lot to try to hide
the details of what's inside

394
00:18:21,250 --> 00:18:23,590
the RTCSessionDescription,
because this includes a whole

395
00:18:23,590 --> 00:18:24,830
bunch of parameters--

396
00:18:24,830 --> 00:18:26,810
as I said, codecs, network
information,

397
00:18:26,810 --> 00:18:27,700
all sorts of stuff--

398
00:18:27,700 --> 00:18:30,190
this is just a snippet of what's
contained inside a

399
00:18:30,190 --> 00:18:32,150
session description right now.

400
00:18:32,150 --> 00:18:34,950
Really advanced apps can do
complex behaviors by modifying

401
00:18:34,950 --> 00:18:38,650
this, but we designed API so
that regular apps just don't

402
00:18:38,650 --> 00:18:39,900
have to think about it.

403
00:18:39,900 --> 00:18:43,840

404
00:18:43,840 --> 00:18:47,170
The other thing that we need
servers for is to actually get

405
00:18:47,170 --> 00:18:49,840
the peer-to-peer session
fully routed.

406
00:18:49,840 --> 00:18:54,062
And in the old days, this
wouldn't be a problem.

407
00:18:54,062 --> 00:18:59,150
A long time ago, each side
had a public IP address.

408
00:18:59,150 --> 00:19:01,190
They send each other's IP
address to each other through

409
00:19:01,190 --> 00:19:03,560
the cloud, and we make the link

410
00:19:03,560 --> 00:19:05,410
directly between the peers.

411
00:19:05,410 --> 00:19:09,690
Well, in the age of NAT, things
are more complicated.

412
00:19:09,690 --> 00:19:12,430
NATs hand out what's called a
private IP address, and these

413
00:19:12,430 --> 00:19:14,990
IP addresses are not useful
for communication.

414
00:19:14,990 --> 00:19:17,990
There's no way we can make the
link actually peer-to-peer

415
00:19:17,990 --> 00:19:21,320
unless we have public address.

416
00:19:21,320 --> 00:19:24,720
So this is where we bring a
technology called STUN.

417
00:19:24,720 --> 00:19:28,250
The STUN server we can contact
from WebRTC, and we say,

418
00:19:28,250 --> 00:19:30,180
what's my public IP address?

419
00:19:30,180 --> 00:19:32,650
And basically, the request comes
into the STUN server, it

420
00:19:32,650 --> 00:19:35,440
sees the address that that
request came from, puts the

421
00:19:35,440 --> 00:19:37,650
address into the packet,
and sends it back.

422
00:19:37,650 --> 00:19:41,000
So now WebRTC knows its public
IP address, and the STUN

423
00:19:41,000 --> 00:19:43,550
server doesn't have to be in
the party anymore, doesn't

424
00:19:43,550 --> 00:19:45,560
have to have media flowing
through it.

425
00:19:45,560 --> 00:19:48,910
So here, if you look at this
example, each side has

426
00:19:48,910 --> 00:19:51,620
contacted that STUN server to
find out what its public IP

427
00:19:51,620 --> 00:19:52,530
address is.

428
00:19:52,530 --> 00:19:55,750
And then it's sent the traffic
to the other IP address

429
00:19:55,750 --> 00:19:59,400
through its NAT, and the data
still flows peer-to-peer.

430
00:19:59,400 --> 00:20:03,720
So this is kind of magic stuff,
and it usually works.

431
00:20:03,720 --> 00:20:06,720
Usually we can make sure that
the data all flows properly

432
00:20:06,720 --> 00:20:09,420
peer-to-peer, but not
in every case.

433
00:20:09,420 --> 00:20:12,120
And for that, we have a
technology called TURN built

434
00:20:12,120 --> 00:20:14,020
into WebRTC.

435
00:20:14,020 --> 00:20:18,310
This turn things around and
provides a cloud fallback when

436
00:20:18,310 --> 00:20:21,940
a peer-to-peer link is
impossible, basically asks for

437
00:20:21,940 --> 00:20:25,040
a relay in the cloud, saying,
give me a public address.

438
00:20:25,040 --> 00:20:26,870
And because this public address
is in the cloud,

439
00:20:26,870 --> 00:20:30,300
anybody can contact it, which
means the call always sets up,

440
00:20:30,300 --> 00:20:32,460
even if you're behind
a restrictive, or

441
00:20:32,460 --> 00:20:34,890
even behind a proxy.

442
00:20:34,890 --> 00:20:37,130
The downside is that since the
data actually is being relayed

443
00:20:37,130 --> 00:20:39,850
through the server, there is
an operational cost to it.

444
00:20:39,850 --> 00:20:41,520
But it does mean the call
works in almost all

445
00:20:41,520 --> 00:20:43,030
environments.

446
00:20:43,030 --> 00:20:46,860
Now, on one hand, we have STUN,
which is super cheap,

447
00:20:46,860 --> 00:20:47,790
but doesn't always work.

448
00:20:47,790 --> 00:20:49,900
And we have TURN, which
always works, but has

449
00:20:49,900 --> 00:20:51,090
some cost to it.

450
00:20:51,090 --> 00:20:55,260
How do we make sure we get
the best of both worlds?

451
00:20:55,260 --> 00:20:59,710
Here's TURN in action, where
we try to use STUN and STUN

452
00:20:59,710 --> 00:21:00,885
didn't work.

453
00:21:00,885 --> 00:21:02,600
And we couldn't get the
things to actually

454
00:21:02,600 --> 00:21:03,600
penetrate the NATs.

455
00:21:03,600 --> 00:21:04,880
So instead, we fell back.

456
00:21:04,880 --> 00:21:08,470
Only then did we use TURN, and
sent the media from our one

457
00:21:08,470 --> 00:21:11,190
peer, through the NAT, through
the TURN server, and to the

458
00:21:11,190 --> 00:21:12,740
other side.

459
00:21:12,740 --> 00:21:15,960
And this is all done by a
technology called ICE.

460
00:21:15,960 --> 00:21:19,640
ICE knows about STUN and TURN,
and tries all the things in

461
00:21:19,640 --> 00:21:22,690
parallel to figure out the
best path for the call.

462
00:21:22,690 --> 00:21:24,990
If it can do STUN,
it does STUN.

463
00:21:24,990 --> 00:21:27,620
If it can do TURN, well then
I'll fall back to TURN, but

464
00:21:27,620 --> 00:21:28,920
I'll do so quickly.

465
00:21:28,920 --> 00:21:31,810
And we have stats from a
deployed WebRTC application

466
00:21:31,810 --> 00:21:34,850
that says 86% of the time,
we can make things

467
00:21:34,850 --> 00:21:36,930
work with just STUN.

468
00:21:36,930 --> 00:21:39,130
So only one out of seven calls
actually have to run through a

469
00:21:39,130 --> 00:21:41,550
TURN server.

470
00:21:41,550 --> 00:21:44,000
So how do you deploy TURN
for your application?

471
00:21:44,000 --> 00:21:48,940
Well, we have some testing
servers, a testing STUN server

472
00:21:48,940 --> 00:21:51,400
that you can use, plus we make
source code available for our

473
00:21:51,400 --> 00:21:52,620
own STUN and TURN server
as part of

474
00:21:52,620 --> 00:21:54,540
the WebRTC code package.

475
00:21:54,540 --> 00:21:57,050
But the thing I would really
recommend is the long name,

476
00:21:57,050 --> 00:21:58,290
but really good product--

477
00:21:58,290 --> 00:22:01,320
rfc5766-turn-server--

478
00:22:01,320 --> 00:22:04,170
which has Amazon VM images
that you can just take,

479
00:22:04,170 --> 00:22:07,270
download, and deploy into the
cloud, and you've got your

480
00:22:07,270 --> 00:22:09,880
TURN server provisioned for all
your users right there.

481
00:22:09,880 --> 00:22:12,900
I also recommend restund,
another TURN server that we've

482
00:22:12,900 --> 00:22:14,150
used with excellent results.

483
00:22:14,150 --> 00:22:18,160

484
00:22:18,160 --> 00:22:20,590
One question that comes up
around WebRTC is, how is

485
00:22:20,590 --> 00:22:22,620
security handled?

486
00:22:22,620 --> 00:22:25,070
And the great thing is that
security has been built into

487
00:22:25,070 --> 00:22:27,850
WebRTC from the very beginning,
and so this means

488
00:22:27,850 --> 00:22:29,860
several different things.

489
00:22:29,860 --> 00:22:32,040
It means we have mandatory
encryption for

490
00:22:32,040 --> 00:22:34,070
both media and data.

491
00:22:34,070 --> 00:22:36,560
So all the data that's being
sent by WebRTC is being

492
00:22:36,560 --> 00:22:40,300
encrypted using standard
AES encryption.

493
00:22:40,300 --> 00:22:42,540
We also have secure UI, meaning
the user's camera

494
00:22:42,540 --> 00:22:45,030
microphone can only be accessed
if they've explicitly

495
00:22:45,030 --> 00:22:47,860
opted in to making that
functionality available.

496
00:22:47,860 --> 00:22:51,050
And last, WebRTC runs inside
the Chrome sandbox.

497
00:22:51,050 --> 00:22:53,720
So even if somebody tries to
attack WebRTC inside of

498
00:22:53,720 --> 00:22:56,395
Chrome, the browser and the user
will be fully protected.

499
00:22:56,395 --> 00:22:58,930

500
00:22:58,930 --> 00:23:00,660
So here's what you need to do
to take advantage of the

501
00:23:00,660 --> 00:23:03,260
security in WebRTC,
is really simple.

502
00:23:03,260 --> 00:23:05,705
Your app just needs
to use HTTPS for

503
00:23:05,705 --> 00:23:07,070
actually doing the signaling.

504
00:23:07,070 --> 00:23:09,710
As long as the signaling goes
over a secure conduit, the

505
00:23:09,710 --> 00:23:12,410
data will be fully secured as
well using the standard

506
00:23:12,410 --> 00:23:16,550
protocols of SRTP for media
or Datagram TLS

507
00:23:16,550 --> 00:23:17,800
for the data channel.

508
00:23:17,800 --> 00:23:21,000

509
00:23:21,000 --> 00:23:23,710
One more question that comes
up is around making a

510
00:23:23,710 --> 00:23:25,810
multi-party call, a
conference call.

511
00:23:25,810 --> 00:23:28,860
How should I architect
my application?

512
00:23:28,860 --> 00:23:31,210
In the simple two-party
case, it's easy.

513
00:23:31,210 --> 00:23:33,200
We just have a peer-to-peer
link.

514
00:23:33,200 --> 00:23:35,800
But as you start adding more
peers into the mix, things get

515
00:23:35,800 --> 00:23:37,270
a bit more complicated.

516
00:23:37,270 --> 00:23:40,510
And one approach that people use
is a mesh, where basically

517
00:23:40,510 --> 00:23:43,220
every peer connects to
every other peer.

518
00:23:43,220 --> 00:23:45,790
And this is really simple,
because there's no servers or

519
00:23:45,790 --> 00:23:49,380
anything involved, other than
the signaling stuff.

520
00:23:49,380 --> 00:23:52,090
But every peer has to send
and copy this data

521
00:23:52,090 --> 00:23:53,220
to every other peer.

522
00:23:53,220 --> 00:23:56,960
So this has a corresponding
CPU and bandwidth cost.

523
00:23:56,960 --> 00:23:59,140
So depending on the media
you're trying to send--

524
00:23:59,140 --> 00:24:00,350
for audio, it can be
kind of higher.

525
00:24:00,350 --> 00:24:02,520
For video, it's going to be
less-- the number of peers you

526
00:24:02,520 --> 00:24:05,680
can support in this topology is
fairly limited, especially

527
00:24:05,680 --> 00:24:09,390
if one of the peers is
on a mobile device.

528
00:24:09,390 --> 00:24:11,650
To deal with that another
architecture that can be used

529
00:24:11,650 --> 00:24:13,730
is the star architecture.

530
00:24:13,730 --> 00:24:16,970
And here, you can pick the most
capable device to be what

531
00:24:16,970 --> 00:24:18,820
we call the focus
for the call.

532
00:24:18,820 --> 00:24:20,970
And the focus is the part that's
actually responsible

533
00:24:20,970 --> 00:24:23,610
for taking the data and sending
a copy to each of the

534
00:24:23,610 --> 00:24:26,020
other endpoints.

535
00:24:26,020 --> 00:24:29,510
But as we get to handing
multiple HD video streams, the

536
00:24:29,510 --> 00:24:31,860
job for a focus becomes
pretty difficult.

537
00:24:31,860 --> 00:24:35,150
And so for the most robust
conferencing architecture, we

538
00:24:35,150 --> 00:24:40,300
recommend an MCU, or multipoint
control unit.

539
00:24:40,300 --> 00:24:43,970
And this is a server that's
custom made for relaying large

540
00:24:43,970 --> 00:24:45,540
amounts of audio and video.

541
00:24:45,540 --> 00:24:46,810
And it can do various things.

542
00:24:46,810 --> 00:24:49,140
It can do selective
stream forwarding.

543
00:24:49,140 --> 00:24:51,660
It can actually mix the
audio or video data.

544
00:24:51,660 --> 00:24:53,700
It can also do things
like recording.

545
00:24:53,700 --> 00:24:56,370
And so if one peer drops out, it
doesn't interrupt the whole

546
00:24:56,370 --> 00:24:58,505
conference, because the MCU is
taking care of everything.

547
00:24:58,505 --> 00:25:02,530

548
00:25:02,530 --> 00:25:05,280
So WebRTC is made with
standards in mind.

549
00:25:05,280 --> 00:25:06,880
And so you can connect
things that

550
00:25:06,880 --> 00:25:09,380
aren't even WebRTC devices.

551
00:25:09,380 --> 00:25:13,160
And one thing that people want
to talk from WebRTC is phones.

552
00:25:13,160 --> 00:25:14,792
And there's a bunch of easy
things they can be dropped

553
00:25:14,792 --> 00:25:16,920
into your web page to
make this happen.

554
00:25:16,920 --> 00:25:20,030
There's a sipML5, which is
a way to talk to various

555
00:25:20,030 --> 00:25:23,710
standard SIP devices, Phono, and
what we're going to show

556
00:25:23,710 --> 00:25:26,861
you now, a widget from Zingaya
to make a phone call.

557
00:25:26,861 --> 00:25:30,550

558
00:25:30,550 --> 00:25:35,950
SAM DUTTON: OK, so we've got a
special guest joining us a

559
00:25:35,950 --> 00:25:37,440
little bit later in
the presentation.

560
00:25:37,440 --> 00:25:40,130
I just wanted to give him a call
to see if he's available.

561
00:25:40,130 --> 00:25:44,890
So let's use the Zingaya
WebRTC phone app now.

562
00:25:44,890 --> 00:25:47,240
And you could see, it's
accessing my microphone.

563
00:25:47,240 --> 00:25:48,090
[PHONE DIALING AND RINGING]

564
00:25:48,090 --> 00:25:49,210
SAM DUTTON: Calling someone.

565
00:25:49,210 --> 00:25:50,510
I hope it's the person I want.

566
00:25:50,510 --> 00:25:54,166
[PHONE RINGING]

567
00:25:54,166 --> 00:25:55,416
SAM DUTTON: See if he's there.

568
00:25:55,416 --> 00:25:59,640

569
00:25:59,640 --> 00:26:00,610
CHRIS WILSON: Hello?

570
00:26:00,610 --> 00:26:02,000
SAM DUTTON: Hey.

571
00:26:02,000 --> 00:26:02,830
Is that you, Chris?

572
00:26:02,830 --> 00:26:03,320
CHRIS WILSON: Hey, Sam.

573
00:26:03,320 --> 00:26:03,950
How's it going?

574
00:26:03,950 --> 00:26:04,290
It is.

575
00:26:04,290 --> 00:26:04,970
SAM DUTTON: Hey.

576
00:26:04,970 --> 00:26:06,260
Fantastic.

577
00:26:06,260 --> 00:26:10,541
I just want to check you're
ready for your gig later on.

578
00:26:10,541 --> 00:26:11,960
CHRIS WILSON: I'm ready
whenever you are.

579
00:26:11,960 --> 00:26:12,970
SAM DUTTON: That's fantastic.

580
00:26:12,970 --> 00:26:14,280
OK, speak to you soon, Chris.

581
00:26:14,280 --> 00:26:14,740
Thanks.

582
00:26:14,740 --> 00:26:15,060
Bye bye.

583
00:26:15,060 --> 00:26:15,990
CHRIS WILSON: Talk
to you soon.

584
00:26:15,990 --> 00:26:16,640
Bye.

585
00:26:16,640 --> 00:26:18,920
SAM DUTTON: Cheers.

586
00:26:18,920 --> 00:26:20,590
JUSTIN UBERTI: It's great--
no plugins, realtime

587
00:26:20,590 --> 00:26:21,840
communication.

588
00:26:21,840 --> 00:26:26,840

589
00:26:26,840 --> 00:26:29,230
SAM DUTTON: Yeah, that
situation, we had

590
00:26:29,230 --> 00:26:30,770
a guy with a telephone.

591
00:26:30,770 --> 00:26:33,630
Something we were thinking
about is situations where

592
00:26:33,630 --> 00:26:36,790
there is no telephone network.

593
00:26:36,790 --> 00:26:40,100
Now, Voxio demonstrated this
with something called Tethr,

594
00:26:40,100 --> 00:26:44,020
which is kind of disaster
communications in a box.

595
00:26:44,020 --> 00:26:48,410
It uses the open BTS cell
framework-- you can see, it's

596
00:26:48,410 --> 00:26:51,630
that little box there-- to
enable calls between feature

597
00:26:51,630 --> 00:26:57,630
phones via the open BTS cell
through WebRTC to computers.

598
00:26:57,630 --> 00:27:00,920
You can imagine this is kind
of fun to get a license for

599
00:27:00,920 --> 00:27:02,780
this in downtown San Francisco,
but this is

600
00:27:02,780 --> 00:27:07,560
incredibly useful in situations
where there is no

601
00:27:07,560 --> 00:27:09,670
infrastructure.

602
00:27:09,670 --> 00:27:11,420
Yeah, this is like telephony
without a

603
00:27:11,420 --> 00:27:12,875
carrier, which is amazing.

604
00:27:12,875 --> 00:27:15,810

605
00:27:15,810 --> 00:27:17,660
JUSTIN UBERTI: So we have a code
lab this afternoon that I

606
00:27:17,660 --> 00:27:19,220
hope you can come to, where
I'll really go into the

607
00:27:19,220 --> 00:27:23,220
details of exactly how to build
a WebRTC application.

608
00:27:23,220 --> 00:27:24,940
But now we're going to talk
about some resources that I

609
00:27:24,940 --> 00:27:27,430
think are really useful.

610
00:27:27,430 --> 00:27:31,050
The first one is something
called WebRTC Internals.

611
00:27:31,050 --> 00:27:34,030
And this is a page you can open
up just by going to this

612
00:27:34,030 --> 00:27:35,950
URL while you're in
a WebRTC call.

613
00:27:35,950 --> 00:27:38,920
And it'll show all sorts of
great statistics about what's

614
00:27:38,920 --> 00:27:42,340
actually happening
inside your call.

615
00:27:42,340 --> 00:27:46,820
This would be things like packet
loss, bandwidth, video

616
00:27:46,820 --> 00:27:48,450
resolution and sizes.

617
00:27:48,450 --> 00:27:51,370
And there's also a full log of
all the calls made to the

618
00:27:51,370 --> 00:27:54,510
WebRTC API that you can
download and export.

619
00:27:54,510 --> 00:27:57,840
So if a customer's reporting
problems with their call, you

620
00:27:57,840 --> 00:27:59,930
can easily get this debugging
information from them.

621
00:27:59,930 --> 00:28:02,450

622
00:28:02,450 --> 00:28:04,520
Another thing is, the
WebRTC spec has been

623
00:28:04,520 --> 00:28:06,520
updating fairly rapidly.

624
00:28:06,520 --> 00:28:09,660
And so in a given browser, the
API might not always match the

625
00:28:09,660 --> 00:28:10,550
latest spec.

626
00:28:10,550 --> 00:28:13,990
Well, adapter.js is something
that's there to insulate the

627
00:28:13,990 --> 00:28:16,680
web developer from the
differences between browsers

628
00:28:16,680 --> 00:28:18,600
and the differences
between versions.

629
00:28:18,600 --> 00:28:21,180
And so we make sure that
adapter.js always implements

630
00:28:21,180 --> 00:28:25,060
the latest spec, and then thunks
down to whatever the

631
00:28:25,060 --> 00:28:26,900
version supports.

632
00:28:26,900 --> 00:28:29,730
So as new APIs are added, we
polyfill them to make sure

633
00:28:29,730 --> 00:28:32,100
that you don't have to write
custom version code or custom

634
00:28:32,100 --> 00:28:33,480
browser code for each browser.

635
00:28:33,480 --> 00:28:34,830
And we use this in our
own applications.

636
00:28:34,830 --> 00:28:37,590

637
00:28:37,590 --> 00:28:41,840
SAM DUTTON: OK, if all this is
too much for you, good news

638
00:28:41,840 --> 00:28:44,660
is, we've got some fantastic
JavaScript frameworks come up

639
00:28:44,660 --> 00:28:48,130
in the last few months, really
great abstraction libraries to

640
00:28:48,130 --> 00:28:51,940
make it really, really simple to
build WebRTC apps just with

641
00:28:51,940 --> 00:28:53,320
a few lines of code.

642
00:28:53,320 --> 00:28:56,240
Example here from SimpleWebRTC,
a little bit of

643
00:28:56,240 --> 00:29:00,370
JavaScript there to specify a
video element that represents

644
00:29:00,370 --> 00:29:02,820
local video, and one that
represents the remote video

645
00:29:02,820 --> 00:29:04,120
stream coming in.

646
00:29:04,120 --> 00:29:07,590
And then join a room just by
calling the joinRoom method

647
00:29:07,590 --> 00:29:08,670
with a room name--

648
00:29:08,670 --> 00:29:10,450
really, really simple.

649
00:29:10,450 --> 00:29:13,840
PeerJS does something similar
for RTCDataChannel--

650
00:29:13,840 --> 00:29:16,660
create a peer, and then on
connection, you can send

651
00:29:16,660 --> 00:29:22,740
messages, receive messages, so
really, really easy to use.

652
00:29:22,740 --> 00:29:25,280
JUSTIN UBERTI: So JavaScript
frameworks go a long way, but

653
00:29:25,280 --> 00:29:26,440
they don't cover the production

654
00:29:26,440 --> 00:29:27,710
aspects of the service--

655
00:29:27,710 --> 00:29:30,420
the signaling, the STUN and TURN
service we talked about.

656
00:29:30,420 --> 00:29:34,115
But fortunately, we have things
from both OpenTok and

657
00:29:34,115 --> 00:29:37,350
Vline that are basically turnkey
WebRTC services that

658
00:29:37,350 --> 00:29:39,512
handle all this stuff for you.

659
00:29:39,512 --> 00:29:42,930
You basically sign up for the
service, get an API key, and

660
00:29:42,930 --> 00:29:44,830
then you can make calls
using their production

661
00:29:44,830 --> 00:29:46,210
infrastructure, which is spread

662
00:29:46,210 --> 00:29:48,420
throughout the entire globe.

663
00:29:48,420 --> 00:29:50,860
They also make UI widgets that
can be easily dropped into

664
00:29:50,860 --> 00:29:52,040
your WebRTC app.

665
00:29:52,040 --> 00:29:57,200
So you get up and running
with WebRTC super fast.

666
00:29:57,200 --> 00:30:01,080
Now, we've got a special
treat for you today.

667
00:30:01,080 --> 00:30:03,640
Chris Wilson, a colleague of
ours, and a developer in the

668
00:30:03,640 --> 00:30:06,690
original Mosaic browser, and
an occasional musician as

669
00:30:06,690 --> 00:30:10,720
well, is going to be joining us
courtesy of WebRTC to show

670
00:30:10,720 --> 00:30:14,820
off the HD video quality and
full-band audio quality that

671
00:30:14,820 --> 00:30:18,850
we're now able to offer in the
latest version of Chrome.

672
00:30:18,850 --> 00:30:20,960
Take it away, Chris.

673
00:30:20,960 --> 00:30:21,600
CHRIS WILSON: Hey, guys.

674
00:30:21,600 --> 00:30:22,350
SAM DUTTON: Hey, Chris.

675
00:30:22,350 --> 00:30:23,362
How's it going?

676
00:30:23,362 --> 00:30:24,040
CHRIS WILSON: I'm good.

677
00:30:24,040 --> 00:30:24,670
How are you?

678
00:30:24,670 --> 00:30:25,860
SAM DUTTON: Yeah, good.

679
00:30:25,860 --> 00:30:28,840
Have you got some kind of
musical instrument with you?

680
00:30:28,840 --> 00:30:29,380
CHRIS WILSON: I do.

681
00:30:29,380 --> 00:30:31,620
You know, originally
you asked me for a

682
00:30:31,620 --> 00:30:33,810
face-melting guitar solo.

683
00:30:33,810 --> 00:30:35,530
But I'm a little more
relaxed now.

684
00:30:35,530 --> 00:30:37,150
I/O is starting to wind down.

685
00:30:37,150 --> 00:30:39,190
You can tell I've already got
my Hawaiian shirt on.

686
00:30:39,190 --> 00:30:40,630
I'm not ready for
some vacation.

687
00:30:40,630 --> 00:30:44,170
So I figured I'd bring my
ukulele and hook it up through

688
00:30:44,170 --> 00:30:48,120
a nice microphone here, so we
can listen to how that sounds.

689
00:30:48,120 --> 00:30:48,670
SAM DUTTON: Take it away.

690
00:30:48,670 --> 00:30:50,710
Melt my face, Chris.

691
00:30:50,710 --> 00:30:55,430
[PLAYING UKULELE]

692
00:30:55,430 --> 00:30:57,192
SAM DUTTON: That's
pretty good.

693
00:30:57,192 --> 00:30:58,442
JUSTIN UBERTI: He's
pretty good.

694
00:30:58,442 --> 00:31:03,110

695
00:31:03,110 --> 00:31:03,400
All right.

696
00:31:03,400 --> 00:31:04,410
SAM DUTTON: That
was beautiful.

697
00:31:04,410 --> 00:31:05,228
Thank you, Chris.

698
00:31:05,228 --> 00:31:06,980
[APPLAUSE]

699
00:31:06,980 --> 00:31:08,300
CHRIS WILSON: All right, guys.

700
00:31:08,300 --> 00:31:09,490
JUSTIN UBERTI: Chris
Wilson, everybody.

701
00:31:09,490 --> 00:31:11,490
SAM DUTTON: The audience
has gone crazy, Chris.

702
00:31:11,490 --> 00:31:14,830
Thank you very much.

703
00:31:14,830 --> 00:31:16,720
JUSTIN UBERTI: You want
to finish up?

704
00:31:16,720 --> 00:31:17,240
SAM DUTTON: Yeah.

705
00:31:17,240 --> 00:31:20,810
So, we've had-- well, a fraction
over 30 minutes to

706
00:31:20,810 --> 00:31:22,380
cover a really big topic.

707
00:31:22,380 --> 00:31:26,010
There's a great lot of more
information out there online,

708
00:31:26,010 --> 00:31:29,270
some good stuff on HTML5 Rocks,
and a really good

709
00:31:29,270 --> 00:31:32,140
e-book too, if you want to
take a look at that.

710
00:31:32,140 --> 00:31:34,860
There are several ways
to contact us.

711
00:31:34,860 --> 00:31:36,570
There's a great Google group--

712
00:31:36,570 --> 00:31:38,280
discuss-webrtc--

713
00:31:38,280 --> 00:31:40,320
post your technical questions.

714
00:31:40,320 --> 00:31:43,670
All the kind of new news for
WebRTC comes through on

715
00:31:43,670 --> 00:31:46,040
Google+ and Twitter stream.

716
00:31:46,040 --> 00:31:49,140
And we're really grateful of
all the people, all of you

717
00:31:49,140 --> 00:31:52,550
who've submitted feature
requests and bugs.

718
00:31:52,550 --> 00:31:56,600
And please keep them coming,
and the URL for that is

719
00:31:56,600 --> 00:31:58,650
crbug.com/new.

720
00:31:58,650 --> 00:32:01,620
So thank you for that.

721
00:32:01,620 --> 00:32:06,500
[APPLAUSE]

722
00:32:06,500 --> 00:32:08,260
JUSTIN UBERTI: And so we've
built this stuff into the web

723
00:32:08,260 --> 00:32:10,980
platform to make realtime
communication

724
00:32:10,980 --> 00:32:12,470
accessible to everyone.

725
00:32:12,470 --> 00:32:15,510
And we're super excited because
we can't wait to see

726
00:32:15,510 --> 00:32:17,410
what you all are
going to build.

727
00:32:17,410 --> 00:32:19,460
So thank you for coming.

728
00:32:19,460 --> 00:32:22,500
Once again, the link.

729
00:32:22,500 --> 00:32:24,310
And now, if you have any
questions, we'll be happy to

730
00:32:24,310 --> 00:32:25,310
try to answer them.

731
00:32:25,310 --> 00:32:26,160
Thank you very much.

732
00:32:26,160 --> 00:32:26,530
SAM DUTTON: Yeah.

733
00:32:26,530 --> 00:32:27,050
Thank you.

734
00:32:27,050 --> 00:32:38,430
[APPLAUSE]

735
00:32:38,430 --> 00:32:38,610
AUDIENCE: Hi.

736
00:32:38,610 --> 00:32:40,450
My name is Mark.

737
00:32:40,450 --> 00:32:43,740
I like to know, because I'm
using Linux and Ubuntu, how

738
00:32:43,740 --> 00:32:46,890
finally can I get rid of the
talk plugin for using Hangouts

739
00:32:46,890 --> 00:32:49,790
in Google+?

740
00:32:49,790 --> 00:32:51,870
JUSTIN UBERTI: The question
is, when can we get rid of

741
00:32:51,870 --> 00:32:53,420
that Hangouts plug-in?

742
00:32:53,420 --> 00:32:55,950
And so unfortunately, we
can only talk about

743
00:32:55,950 --> 00:32:57,010
WebRTC matters today.

744
00:32:57,010 --> 00:32:58,090
That's handled by
another team.

745
00:32:58,090 --> 00:32:59,820
But let's say that there
are many of us who

746
00:32:59,820 --> 00:33:01,210
have the same feeling.

747
00:33:01,210 --> 00:33:01,485
AUDIENCE: OK.

748
00:33:01,485 --> 00:33:02,210
Great.

749
00:33:02,210 --> 00:33:05,360
[LAUGHTER]

750
00:33:05,360 --> 00:33:07,920
AUDIENCE: Can you make any
comments on Microsoft's

751
00:33:07,920 --> 00:33:11,630
competing standard, considering
they kind of hold

752
00:33:11,630 --> 00:33:16,670
the cards with Skype, and how
maybe we can go forward

753
00:33:16,670 --> 00:33:20,430
supporting both or maybe
converge the two, or just your

754
00:33:20,430 --> 00:33:22,230
thoughts on that?

755
00:33:22,230 --> 00:33:26,110
JUSTIN UBERTI: So Microsoft
has actually been a great

756
00:33:26,110 --> 00:33:27,560
participant in standards.

757
00:33:27,560 --> 00:33:30,460
They have several people they
sent from their team.

758
00:33:30,460 --> 00:33:33,140
And although they don't see
things exactly the same way

759
00:33:33,140 --> 00:33:37,110
that we do, I think that the API
differences are sort of,

760
00:33:37,110 --> 00:33:39,290
theirs is a lot more low-level,
geared for expert

761
00:33:39,290 --> 00:33:39,800
developers.

762
00:33:39,800 --> 00:33:41,990
Ours is a little more
high-level, geared for web

763
00:33:41,990 --> 00:33:42,920
developers.

764
00:33:42,920 --> 00:33:46,020
And I think that really what
you can do is you can

765
00:33:46,020 --> 00:33:48,830
implement the high-level one on
top of the low-level one,

766
00:33:48,830 --> 00:33:50,360
maybe even vice versa.

767
00:33:50,360 --> 00:33:55,190
So Microsoft is a little more
secretive about what they do.

768
00:33:55,190 --> 00:33:57,300
So we don't know exactly
what their timeframe

769
00:33:57,300 --> 00:33:58,670
is relative to IE.

770
00:33:58,670 --> 00:34:00,500
But they're fully
participating.

771
00:34:00,500 --> 00:34:02,470
And obviously, they're very
interested in Skype.

772
00:34:02,470 --> 00:34:06,070
So I'm very optimistic that
we'll see a version of IE that

773
00:34:06,070 --> 00:34:09,170
supports this technology in the
not-too-distant future.

774
00:34:09,170 --> 00:34:09,679
AUDIENCE: Very good to hear.

775
00:34:09,679 --> 00:34:10,929
Thank you.

776
00:34:10,929 --> 00:34:12,909

777
00:34:12,909 --> 00:34:15,500
AUDIENCE: My question would be,
I think you mentioned it

778
00:34:15,500 --> 00:34:16,540
quickly in the beginning.

779
00:34:16,540 --> 00:34:20,090
So if I wanted to communicate
with WebRTC, but one, I'm

780
00:34:20,090 --> 00:34:21,679
using a different environment
than the browser.

781
00:34:21,679 --> 00:34:24,800
Let's say I want a web
application to speak to a

782
00:34:24,800 --> 00:34:25,510
native Android app.

783
00:34:25,510 --> 00:34:29,550
So what would be the approach to
integrate that with WebRTC?

784
00:34:29,550 --> 00:34:31,620
JUSTIN UBERTI: As I mentioned
earlier, we have a fully

785
00:34:31,620 --> 00:34:35,780
supported official native
version of pure connection,

786
00:34:35,780 --> 00:34:38,420
PureConnection.Java, which is
open source, and you can

787
00:34:38,420 --> 00:34:40,330
download, and you can build
that into your native

788
00:34:40,330 --> 00:34:41,179
application.

789
00:34:41,179 --> 00:34:42,159
And it interoperates.

790
00:34:42,159 --> 00:34:43,790
We have a demo app that
interoperates with

791
00:34:43,790 --> 00:34:45,670
our AppRTC demo app.

792
00:34:45,670 --> 00:34:51,340
So I think that using Chrome for
Android in a web view is

793
00:34:51,340 --> 00:34:52,639
one thing you can think about.

794
00:34:52,639 --> 00:34:54,969
But if that doesn't work for
you, we have a native version

795
00:34:54,969 --> 00:34:56,360
that works great.

796
00:34:56,360 --> 00:34:56,659
AUDIENCE: OK.

797
00:34:56,659 --> 00:34:58,890
Thank you.

798
00:34:58,890 --> 00:34:59,460
AUDIENCE: Hi.

799
00:34:59,460 --> 00:35:02,690
My question would be, are there
any things that to be

800
00:35:02,690 --> 00:35:05,370
taken care between cross-browser
compatibility

801
00:35:05,370 --> 00:35:08,550
for this Firefox Chrome?

802
00:35:08,550 --> 00:35:10,170
Anything specific that
needs to be taken

803
00:35:10,170 --> 00:35:12,750
care, or it just works?

804
00:35:12,750 --> 00:35:14,480
JUSTIN UBERTI: There are
some minor differences.

805
00:35:14,480 --> 00:35:17,720
I mentioned adapter.js covers
some of the things where the

806
00:35:17,720 --> 00:35:21,190
API isn't quite in sync
in both places.

807
00:35:21,190 --> 00:35:25,470
One specific thing is that
Firefox only supports the opus

808
00:35:25,470 --> 00:35:28,780
codec, and they only support
DTLS encryption.

809
00:35:28,780 --> 00:35:32,040
They don't support something
called S-DES,

810
00:35:32,040 --> 00:35:33,290
that we also support.

811
00:35:33,290 --> 00:35:37,880
So for right now, you have to
set one parameter in the API,

812
00:35:37,880 --> 00:35:42,500
and you can see that in our app
RTC source code, to make

813
00:35:42,500 --> 00:35:44,870
sure that communication
actually uses

814
00:35:44,870 --> 00:35:46,370
those compatible protocols.

815
00:35:46,370 --> 00:35:48,530
We actually have a document,
though, on our web page, the

816
00:35:48,530 --> 00:35:51,130
documents exactly what you have
to do, which is really

817
00:35:51,130 --> 00:35:53,890
setting a single constraint
parameter when you're creating

818
00:35:53,890 --> 00:35:55,020
your peer connection object.

819
00:35:55,020 --> 00:35:55,480
SAM DUTTON: Yeah.

820
00:35:55,480 --> 00:35:58,120
If you go to webrtc.org/interop.

821
00:35:58,120 --> 00:35:58,450
JUSTIN UBERTI: Yeah.

822
00:35:58,450 --> 00:36:00,280
That works at org/interop.

823
00:36:00,280 --> 00:36:00,700
AUDIENCE: OK.

824
00:36:00,700 --> 00:36:03,170
Thank you.

825
00:36:03,170 --> 00:36:05,180
AUDIENCE: When a peer connection
is made and it

826
00:36:05,180 --> 00:36:11,020
falls back to TURN, does the
TURN server, is it capable of

827
00:36:11,020 --> 00:36:14,740
unencrypting the messages that
go between the two endpoints?

828
00:36:14,740 --> 00:36:15,170
JUSTIN UBERTI: No.

829
00:36:15,170 --> 00:36:17,480
The TURN server is just
a packet relay.

830
00:36:17,480 --> 00:36:19,340
So this stuff is fully
encrypted.

831
00:36:19,340 --> 00:36:21,150
It doesn't have the keying
information to

832
00:36:21,150 --> 00:36:21,860
do anything to it.

833
00:36:21,860 --> 00:36:25,285
So the TURN server just takes a
byte, sends a byte, takes a

834
00:36:25,285 --> 00:36:28,260
packet, sends a packet.

835
00:36:28,260 --> 00:36:30,960
AUDIENCE: So for keeping data
in sync with low latency

836
00:36:30,960 --> 00:36:34,670
between, say, an Android
application and the server,

837
00:36:34,670 --> 00:36:42,210
how would both the native
and the Android Chrome

838
00:36:42,210 --> 00:36:46,770
implementations of WebRTC fare
in terms of battery life?

839
00:36:46,770 --> 00:36:50,900
JUSTIN UBERTI: I don't really
have a good answer for that.

840
00:36:50,900 --> 00:36:52,410
I wouldn't think there would
be much difference.

841
00:36:52,410 --> 00:36:54,010
I mean, the key things that
are going to be driving

842
00:36:54,010 --> 00:36:55,990
battery consumption
in this case--

843
00:36:55,990 --> 00:36:57,180
are you talking about data,
or are you talking

844
00:36:57,180 --> 00:36:58,910
about audio and video?

845
00:36:58,910 --> 00:37:00,150
AUDIENCE: Data.

846
00:37:00,150 --> 00:37:01,800
JUSTIN UBERTI: For data, the
key drivers of your power

847
00:37:01,800 --> 00:37:04,330
consumption are going to be the
screen and the network.

848
00:37:04,330 --> 00:37:07,490
And so I think those should be
comparable between Chrome for

849
00:37:07,490 --> 00:37:09,900
Android and the native
application.

850
00:37:09,900 --> 00:37:10,620
AUDIENCE: OK, cool.

851
00:37:10,620 --> 00:37:11,870
Thanks.

852
00:37:11,870 --> 00:37:14,370

853
00:37:14,370 --> 00:37:18,380
AUDIENCE: With two computers
running Chrome, or what have

854
00:37:18,380 --> 00:37:22,180
you seen glass-to-glass
latency?

855
00:37:22,180 --> 00:37:23,240
JUSTIN UBERTI: Repeat?

856
00:37:23,240 --> 00:37:25,790
AUDIENCE: Glass-to-glass, so
from the camera to the LCD.

857
00:37:25,790 --> 00:37:27,040
JUSTIN UBERTI: Oh, yeah.

858
00:37:27,040 --> 00:37:29,270

859
00:37:29,270 --> 00:37:32,700
So it depends on a platform,
because the camera can have a

860
00:37:32,700 --> 00:37:36,290
large delay built
into it itself.

861
00:37:36,290 --> 00:37:41,060
Also, some of the audio
things have higher

862
00:37:41,060 --> 00:37:41,590
latencies than others.

863
00:37:41,590 --> 00:37:44,770
But the overall target is 150
milliseconds end-to-end.

864
00:37:44,770 --> 00:37:48,530
And we've seen lower than 100
milliseconds in best case

865
00:37:48,530 --> 00:37:51,286
solutions for glass-to-glass
type latency.

866
00:37:51,286 --> 00:37:51,640
AUDIENCE: OK.

867
00:37:51,640 --> 00:37:56,495
And how are you ensuring
priority of your data across

868
00:37:56,495 --> 00:37:58,780
the network?

869
00:37:58,780 --> 00:38:00,880
JUSTIN UBERTI: That's a complex

870
00:38:00,880 --> 00:38:03,150
question with a long answer.

871
00:38:03,150 --> 00:38:05,720
But the basic thing, are you
saying, how do we compete with

872
00:38:05,720 --> 00:38:06,965
cat videos?

873
00:38:06,965 --> 00:38:11,340
AUDIENCE: No, just within the
WebRTC, are you just--

874
00:38:11,340 --> 00:38:14,350
how are you tagging
your packets?

875
00:38:14,350 --> 00:38:18,590
JUSTIN UBERTI: Right, so there
is something called DSCP where

876
00:38:18,590 --> 00:38:21,290
we can mark QoS bits-- and this
isn't yet implemented in

877
00:38:21,290 --> 00:38:24,040
WebRTC, but it's on the roadmap,
to be able to tag

878
00:38:24,040 --> 00:38:26,710
things like audio as higher
priority than, say, video, and

879
00:38:26,710 --> 00:38:30,100
that as a higher priority
than cat videos.

880
00:38:30,100 --> 00:38:32,390
AUDIENCE: So it's not today,
but will be done?

881
00:38:32,390 --> 00:38:32,820
JUSTIN UBERTI: It
will be done.

882
00:38:32,820 --> 00:38:37,070
We also have things for doing
FEC type mechanisms to protect

883
00:38:37,070 --> 00:38:38,580
things at the application
layer.

884
00:38:38,580 --> 00:38:42,490
But the expectation is that as
WebRTC becomes more pervasive,

885
00:38:42,490 --> 00:38:47,540
carriers will support DSCP at
least on the bit from coming

886
00:38:47,540 --> 00:38:49,500
off the computer and going
onto their network.

887
00:38:49,500 --> 00:38:52,110
And we have that DSCP does
help going through Wi-Fi

888
00:38:52,110 --> 00:38:55,240
access points, because Wi-Fi
access points to give priority

889
00:38:55,240 --> 00:38:56,900
to DSCP-marked traffic.

890
00:38:56,900 --> 00:38:58,150
AUDIENCE: Thank you.

891
00:38:58,150 --> 00:39:00,410

892
00:39:00,410 --> 00:39:04,640
AUDIENCE: So in Chrome for iOS
being limited to UI web view

893
00:39:04,640 --> 00:39:08,110
and with other restrictions, how
much of WebRTC will you be

894
00:39:08,110 --> 00:39:10,310
able to implement?

895
00:39:10,310 --> 00:39:12,820
JUSTIN UBERTI: So that's a
really interesting question.

896
00:39:12,820 --> 00:39:16,220
They haven't made it easy for
us, but the Chrome for iOS

897
00:39:16,220 --> 00:39:18,660
team has already done some
amazing things to deliver the

898
00:39:18,660 --> 00:39:20,470
Chrome experience that
exists there now.

899
00:39:20,470 --> 00:39:23,470
And so we're pretty optimistic
that one way or another, we

900
00:39:23,470 --> 00:39:25,130
can find some way to
make that work.

901
00:39:25,130 --> 00:39:29,680
No commitment to the
time frame, though.

902
00:39:29,680 --> 00:39:32,480
AUDIENCE: What are the
mechanisms for a saving video

903
00:39:32,480 --> 00:39:38,600
and audio that's broadcast with
WebRTC, like making video

904
00:39:38,600 --> 00:39:41,120
recordings from it?

905
00:39:41,120 --> 00:39:43,590
JUSTIN UBERTI: So if you have
the media stream, you can then

906
00:39:43,590 --> 00:39:46,290
take the media stream and plug
it into things like the Web

907
00:39:46,290 --> 00:39:48,700
Rdio API, where you can actually
get the raw samples,

908
00:39:48,700 --> 00:39:51,450
and then make a wave file
and save that out.

909
00:39:51,450 --> 00:39:53,600
On the video side, you can go
into a canvas, and then

910
00:39:53,600 --> 00:39:55,880
extract the frames from a
canvas, and you can save that.

911
00:39:55,880 --> 00:40:00,250
There isn't really any way to
sort of save it as a .MP4,

912
00:40:00,250 --> 00:40:03,440
.WEBM file yet.

913
00:40:03,440 --> 00:40:06,480
But if you want to make a thing
that just captures audio

914
00:40:06,480 --> 00:40:09,390
from the computer then it stores
on a server, you could

915
00:40:09,390 --> 00:40:11,300
basically make a custom server
that could do that recording.

916
00:40:11,300 --> 00:40:12,720
That's one option.

917
00:40:12,720 --> 00:40:14,180
AUDIENCE: So the TURN
server is open--

918
00:40:14,180 --> 00:40:17,760
but you said the TURN server
doesn't capture.

919
00:40:17,760 --> 00:40:17,880
JUSTIN UBERTI: No.

920
00:40:17,880 --> 00:40:19,420
AUDIENCE: It can't act
as an endpoint.

921
00:40:19,420 --> 00:40:21,810
Do you have server technology
that acts as an endpoint?

922
00:40:21,810 --> 00:40:22,720
JUSTIN UBERTI: There
are people building

923
00:40:22,720 --> 00:40:25,170
this sort of stuff.

924
00:40:25,170 --> 00:40:29,370
Vline might be one particular
vendor who does this, but

925
00:40:29,370 --> 00:40:31,780
there's something where you can
basically have an MCU, and

926
00:40:31,780 --> 00:40:33,850
the MCU that receives the media
could then do things

927
00:40:33,850 --> 00:40:36,280
like compositing or recording
of that media.

928
00:40:36,280 --> 00:40:39,020
AUDIENCE: So presumably, the
libraries for Java or

929
00:40:39,020 --> 00:40:41,400
Objective C could be used
to create a server

930
00:40:41,400 --> 00:40:41,720
implementation?

931
00:40:41,720 --> 00:40:42,210
JUSTIN UBERTI: Exactly.

932
00:40:42,210 --> 00:40:45,130
That's what they're doing.

933
00:40:45,130 --> 00:40:47,330
AUDIENCE: Hi, kind of two-part
question that has to do around

934
00:40:47,330 --> 00:40:49,800
codecs, specifically
on the video side,

935
00:40:49,800 --> 00:40:52,260
currently VP8, WebM.

936
00:40:52,260 --> 00:40:54,530
Is there plans for H.264,
and also what's the

937
00:40:54,530 --> 00:40:56,630
timeline for VP9?

938
00:40:56,630 --> 00:40:58,560
JUSTIN UBERTI: Our plans are
around the VP family of

939
00:40:58,560 --> 00:41:00,240
codecs, so we support VP8.

940
00:41:00,240 --> 00:41:03,600
And VP9, you may have heard that
it's sort of trying to

941
00:41:03,600 --> 00:41:05,620
finalize the bit stream
right now.

942
00:41:05,620 --> 00:41:07,880
So we are very much looking
forward to taking advantage of

943
00:41:07,880 --> 00:41:11,280
VP9 with all its new coding
techniques, once it's both

944
00:41:11,280 --> 00:41:13,980
finished and also optimized
for realtime.

945
00:41:13,980 --> 00:41:16,580
AUDIENCE: And H.264, not
really on the plan?

946
00:41:16,580 --> 00:41:20,050
JUSTIN UBERTI: We think that
VP9 provides much better

947
00:41:20,050 --> 00:41:22,550
compression and overall
performance than H.264, so we

948
00:41:22,550 --> 00:41:24,596
have no plans as far as
H.264 at this time.

949
00:41:24,596 --> 00:41:25,846
AUDIENCE: OK.

950
00:41:25,846 --> 00:41:27,720

951
00:41:27,720 --> 00:41:30,540
AUDIENCE: Running WebRTC on
Chrome or Android for mobile

952
00:41:30,540 --> 00:41:35,020
and tablets, how does it
compare with native

953
00:41:35,020 --> 00:41:38,270
performance, like Hangouts
on Android?

954
00:41:38,270 --> 00:41:39,970
JUSTIN UBERTI: We think that
we provide a comparable

955
00:41:39,970 --> 00:41:43,080
performance to any native
application right now.

956
00:41:43,080 --> 00:41:44,860
We're always trying to
make things better.

957
00:41:44,860 --> 00:41:47,960
We still have Chrome for
Android, the WebRTC's behind a

958
00:41:47,960 --> 00:41:50,800
flag because we still have work
to do around improving

959
00:41:50,800 --> 00:41:52,640
audio, improvement some
of the performance.

960
00:41:52,640 --> 00:41:54,520
But we think we can deliver
equivalent performance on the

961
00:41:54,520 --> 00:41:55,600
web browser.

962
00:41:55,600 --> 00:41:57,580
And we're also working on taking
advantage of hardware

963
00:41:57,580 --> 00:42:00,520
acceleration, in cases where
there's hardware decoders like

964
00:42:00,520 --> 00:42:03,980
there is on Nexus 10, and making
that so we can get the

965
00:42:03,980 --> 00:42:06,515
same sort of down-to-the-metal
performance that you could get

966
00:42:06,515 --> 00:42:07,765
from a native app.

967
00:42:07,765 --> 00:42:10,720

968
00:42:10,720 --> 00:42:13,490
AUDIENCE: So the Google Talk
plugin is using not just

969
00:42:13,490 --> 00:42:19,050
H.264, but H.264 SVC optimized
for the needs of

970
00:42:19,050 --> 00:42:19,690
videoconferencing.

971
00:42:19,690 --> 00:42:23,540
Is VP8 and VP9 going to
be similarly optimized

972
00:42:23,540 --> 00:42:27,860
specifically in an SVC-like
fashion for video conferencing

973
00:42:27,860 --> 00:42:31,942
versus just the versions
for file encoding?

974
00:42:31,942 --> 00:42:35,010
JUSTIN UBERTI: So VP8 already
supports temporal scalability

975
00:42:35,010 --> 00:42:38,590
in the S part of SVC.

976
00:42:38,590 --> 00:42:41,550
VP9 supports additional
scalability modes as well.

977
00:42:41,550 --> 00:42:43,805
So we're very excited about the
new coding techniques that

978
00:42:43,805 --> 00:42:46,150
are coming in VP9.

979
00:42:46,150 --> 00:42:50,620
AUDIENCE: So we want to use
WebRTC to do live streaming

980
00:42:50,620 --> 00:42:55,370
from, let's say, cameras,
hardware cameras.

981
00:42:55,370 --> 00:43:00,790
And what are the things that
we should take care of such

982
00:43:00,790 --> 00:43:02,070
kind of an application?

983
00:43:02,070 --> 00:43:04,640
And when you mentioned
VP8 and VP9 support,

984
00:43:04,640 --> 00:43:06,340
H.264 is not supported.

985
00:43:06,340 --> 00:43:09,430
Assuming your hardware supports
only H.264, WebRTC

986
00:43:09,430 --> 00:43:12,440
can be used with Chrome
in that case?

987
00:43:12,440 --> 00:43:16,200
JUSTIN UBERTI: We are building
up support for hardware VP8,

988
00:43:16,200 --> 00:43:17,845
and later, VP9 encoders.

989
00:43:17,845 --> 00:43:20,810

990
00:43:20,810 --> 00:43:24,380
So you can make a media
streaming application like you

991
00:43:24,380 --> 00:43:28,875
described, but we're expecting
that all the major SSE vendors

992
00:43:28,875 --> 00:43:31,580
are now shipping hardware
with built-in VP8

993
00:43:31,580 --> 00:43:33,120
encoders and decoders.

994
00:43:33,120 --> 00:43:35,720
So as this stuff gets into
market, you're going to see

995
00:43:35,720 --> 00:43:39,540
this stuff become the most
efficient way to record and

996
00:43:39,540 --> 00:43:41,190
compress data.

997
00:43:41,190 --> 00:43:44,095
AUDIENCE: So the only way is
to support VP8 in hardware

998
00:43:44,095 --> 00:43:45,345
right now, right?

999
00:43:45,345 --> 00:43:48,750

1000
00:43:48,750 --> 00:43:52,290
JUSTIN UBERTI: If you want
hardware compression, the only

1001
00:43:52,290 --> 00:43:55,810
things that we support right
now will be VP8 encoders.

1002
00:43:55,810 --> 00:43:57,590
AUDIENCE: That's on the device
side, you know, the camera

1003
00:43:57,590 --> 00:43:58,970
which is on--

1004
00:43:58,970 --> 00:44:00,310
JUSTIN UBERTI: Right.

1005
00:44:00,310 --> 00:44:02,670
If you're having encoding from
a device that you want to be

1006
00:44:02,670 --> 00:44:08,030
decoded within the browser, I
advise you to do it in VP8.

1007
00:44:08,030 --> 00:44:09,280
AUDIENCE: Thank you.

1008
00:44:09,280 --> 00:44:11,330

1009
00:44:11,330 --> 00:44:12,430
JUSTIN UBERTI: Thank
you all for coming.

1010
00:44:12,430 --> 00:44:13,030
SAM DUTTON: Yeah, thank you.

1011
00:44:13,030 --> 00:44:16,965
[APPLAUSE]

