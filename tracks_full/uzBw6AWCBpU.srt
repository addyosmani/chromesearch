1
00:00:00,000 --> 00:00:01,510

2
00:00:01,510 --> 00:00:02,330
TIM MURRAY: All right.

3
00:00:02,330 --> 00:00:03,310
Good morning, everyone.

4
00:00:03,310 --> 00:00:04,350
My name is Tim Murray.

5
00:00:04,350 --> 00:00:07,370
I'm an engineer at Google on
the RenderScript team.

6
00:00:07,370 --> 00:00:09,860
And we're here to talk about
writing high performance

7
00:00:09,860 --> 00:00:13,080
applications with
RenderScript.

8
00:00:13,080 --> 00:00:17,420
So first, I'd like to talk
about GPUs in general.

9
00:00:17,420 --> 00:00:21,270
So in the past seven years or
so, GPUs have become useful

10
00:00:21,270 --> 00:00:23,400
for a lot more applications
than

11
00:00:23,400 --> 00:00:25,450
just traditional graphics.

12
00:00:25,450 --> 00:00:28,300
And the reason for this is that
they have a lot of flops

13
00:00:28,300 --> 00:00:31,540
and a lot of memory bandwidth
verses CPUs.

14
00:00:31,540 --> 00:00:34,340
And so they're really good at
data parallel tasks that

15
00:00:34,340 --> 00:00:38,350
happen to look sort
of like graphics.

16
00:00:38,350 --> 00:00:42,050
And the market where this has
had the most adoption is in

17
00:00:42,050 --> 00:00:44,930
high performance computing,
supercomputing, oil and gas,

18
00:00:44,930 --> 00:00:46,170
things like that.

19
00:00:46,170 --> 00:00:49,670
The current number one machine
on the top 500 is primarily

20
00:00:49,670 --> 00:00:51,920
GPU based, for example.

21
00:00:51,920 --> 00:00:54,540
And now in mobile, we're
starting to see these

22
00:00:54,540 --> 00:00:58,840
programmable GPUs arrive
and become useful.

23
00:00:58,840 --> 00:01:01,930
But before we go into mobile,
I want to talk a little bit

24
00:01:01,930 --> 00:01:05,300
about a traditional
desktop, or server

25
00:01:05,300 --> 00:01:07,760
architecture with a GPU.

26
00:01:07,760 --> 00:01:10,980
So the first thing you'll notice
is that in terms of raw

27
00:01:10,980 --> 00:01:14,030
computational throughput,
floating point, memory

28
00:01:14,030 --> 00:01:18,020
bandwidth, things like that,
the GPU dominates the CPU.

29
00:01:18,020 --> 00:01:19,880
It's got four times the
memory bandwidth.

30
00:01:19,880 --> 00:01:24,410
It's got 10 to 15 times the
flop on a high end GPU.

31
00:01:24,410 --> 00:01:26,560
However, there's a problem,
and that's

32
00:01:26,560 --> 00:01:28,870
the PCI express bus.

33
00:01:28,870 --> 00:01:31,500
The PCI express bus is something
that all your data

34
00:01:31,500 --> 00:01:35,800
has to traverse in order to move
from the GPU to the CPU,

35
00:01:35,800 --> 00:01:37,650
or vice versa.

36
00:01:37,650 --> 00:01:41,760
And compared to the speed of
memory bandwidth on either

37
00:01:41,760 --> 00:01:43,690
device, it's very slow.

38
00:01:43,690 --> 00:01:46,120
So a lot of the work in porting
an application to the

39
00:01:46,120 --> 00:01:49,820
GPU and desktop comes from
managing this data transfer

40
00:01:49,820 --> 00:01:52,360
overhead, and only moving work
to the GPU when you can

41
00:01:52,360 --> 00:01:56,250
actually amortize the cost of
moving data to the GPU.

42
00:01:56,250 --> 00:01:59,220

43
00:01:59,220 --> 00:02:01,820
In mobile, things look
very different.

44
00:02:01,820 --> 00:02:04,165
The first thing you'll notice
is that the GPU and the CPU

45
00:02:04,165 --> 00:02:06,290
are now in the same package.

46
00:02:06,290 --> 00:02:09,070
They share a single pool
of physical memory.

47
00:02:09,070 --> 00:02:11,290
So there's no more
PCI express bus.

48
00:02:11,290 --> 00:02:13,120
That transfer time is gone.

49
00:02:13,120 --> 00:02:15,210
However, this does mean that
because they share the same

50
00:02:15,210 --> 00:02:18,430
pool of physical memory, the
GPU no longer has a number

51
00:02:18,430 --> 00:02:19,670
bandwidth advantage.

52
00:02:19,670 --> 00:02:23,330
And to further reduce the GPU's
advantage, its floating

53
00:02:23,330 --> 00:02:27,190
point performance relative to
the CPU is now only about

54
00:02:27,190 --> 00:02:29,090
three to four times faster.

55
00:02:29,090 --> 00:02:32,870
We're not talking 10 to 15
times faster anymore.

56
00:02:32,870 --> 00:02:35,000
We also may have additional
processors

57
00:02:35,000 --> 00:02:36,400
available to us in mobile.

58
00:02:36,400 --> 00:02:40,900
For example, you could have a
camera ISP that can do things

59
00:02:40,900 --> 00:02:43,800
like color space conversion
or basic convolution, or

60
00:02:43,800 --> 00:02:45,380
something like that.

61
00:02:45,380 --> 00:02:47,470
And you may have a
programmable DSP

62
00:02:47,470 --> 00:02:49,640
on your SoC as well.

63
00:02:49,640 --> 00:02:53,860
And you may really want to
use these processors when

64
00:02:53,860 --> 00:02:57,150
possible, because they're
relatively fixed function.

65
00:02:57,150 --> 00:02:59,530
And they may provide very,
very good perf per watt.

66
00:02:59,530 --> 00:03:02,980

67
00:03:02,980 --> 00:03:05,070
So in terms of architecture,
mobile

68
00:03:05,070 --> 00:03:06,510
versus desktop is different.

69
00:03:06,510 --> 00:03:08,530
And it's different in more
than just the block

70
00:03:08,530 --> 00:03:10,430
diagram ways, too.

71
00:03:10,430 --> 00:03:13,530
Mobile has a lot of
architectural diversity.

72
00:03:13,530 --> 00:03:18,530
In desktop you have two CPU
vendors, three GPU vendors.

73
00:03:18,530 --> 00:03:21,740
In mobile you have
three CPU ISAs.

74
00:03:21,740 --> 00:03:25,820
Within ARM, you have a number
of different ARM cores and

75
00:03:25,820 --> 00:03:27,910
licensed ARM cores.

76
00:03:27,910 --> 00:03:32,180
You have dramatically more
GPUs and GPU vendors.

77
00:03:32,180 --> 00:03:36,620
And particularly within the GPU
space, the architecture of

78
00:03:36,620 --> 00:03:41,210
these GPUs are very different
from one another.

79
00:03:41,210 --> 00:03:44,040
If you look at a kind of desktop
GPUs, in broad strokes

80
00:03:44,040 --> 00:03:46,010
they look mostly similar.

81
00:03:46,010 --> 00:03:47,690
That's not true in mobile.

82
00:03:47,690 --> 00:03:50,560
Some of them look very CPU like,
and have very small SIMD

83
00:03:50,560 --> 00:03:52,930
widths, and things like that.

84
00:03:52,930 --> 00:03:56,550
Others look more like
traditional desktop GPUs, and

85
00:03:56,550 --> 00:03:59,930
then they have very wide
vector widths.

86
00:03:59,930 --> 00:04:01,690
Others look sort of
like a pool of

87
00:04:01,690 --> 00:04:04,610
fixed function hardware.

88
00:04:04,610 --> 00:04:07,680
And additionally in mobile, and
you have concerns about

89
00:04:07,680 --> 00:04:09,250
system resources.

90
00:04:09,250 --> 00:04:13,100
The biggest two there are power
and thermal constraints,

91
00:04:13,100 --> 00:04:16,630
which generally don't affect
you as much on desktop.

92
00:04:16,630 --> 00:04:20,220
You also have issues like the
GPU may be busy rendering a

93
00:04:20,220 --> 00:04:21,410
lot of pixels.

94
00:04:21,410 --> 00:04:26,540
For example on a Nexux 10, we
have a 2560x1600 display,

95
00:04:26,540 --> 00:04:29,770
which is equivalent to a 30
inch desktop monitor.

96
00:04:29,770 --> 00:04:32,900
And we're trying to drive that
on the GPU with 80 gigaflops,

97
00:04:32,900 --> 00:04:36,050
instead of over a teraflop.

98
00:04:36,050 --> 00:04:37,870
And you may have additional
processors that you want to

99
00:04:37,870 --> 00:04:39,700
use as well.

100
00:04:39,700 --> 00:04:42,990
So our goal here is really to
develop high performance

101
00:04:42,990 --> 00:04:48,060
applications for these wide
variety of SoCs without

102
00:04:48,060 --> 00:04:49,720
sacrificing performance
portability.

103
00:04:49,720 --> 00:04:55,000
Without guaranteeing that the
more you optimize for one SoC,

104
00:04:55,000 --> 00:04:58,960
the worse you run on
certain other SoCs.

105
00:04:58,960 --> 00:05:03,190
So our approach to solving that
is called RenderScript.

106
00:05:03,190 --> 00:05:05,710
And RenderScript is our platform
for high performance

107
00:05:05,710 --> 00:05:09,300
computing across different
hardware on Android.

108
00:05:09,300 --> 00:05:12,020
So the first thing you'll notice
about the API is that

109
00:05:12,020 --> 00:05:13,660
the API is focused
on the system.

110
00:05:13,660 --> 00:05:15,040
You don't get a list
of devices.

111
00:05:15,040 --> 00:05:17,680
You don't get a big collection
of device properties and have

112
00:05:17,680 --> 00:05:19,760
to try to figure out
at run time which

113
00:05:19,760 --> 00:05:21,000
device you should use.

114
00:05:21,000 --> 00:05:22,610
The runtime handles
that for you.

115
00:05:22,610 --> 00:05:26,620
You simply have a computation
that you want to run quickly,

116
00:05:26,620 --> 00:05:30,010
and we will try to put that on
the best processor we can.

117
00:05:30,010 --> 00:05:33,080
What this means is that this
gives developers a consistent

118
00:05:33,080 --> 00:05:36,100
target that will run well
across any SoC.

119
00:05:36,100 --> 00:05:41,760
We work with the SoC vendors and
get drivers for their GPUs

120
00:05:41,760 --> 00:05:46,570
and DSPs, ISPs, whatever, and
have those available on

121
00:05:46,570 --> 00:05:48,440
tablets and phones.

122
00:05:48,440 --> 00:05:53,980
And this way, the runtime
knows about whatever

123
00:05:53,980 --> 00:05:56,650
processors and capabilities
it can use.

124
00:05:56,650 --> 00:06:00,660
It doesn't require the developer
to go in and may

125
00:06:00,660 --> 00:06:03,860
call these decisions at run time
about an SoC it's never

126
00:06:03,860 --> 00:06:05,660
seen before.

127
00:06:05,660 --> 00:06:09,080
We've been influenced by other
data parallel run times,

128
00:06:09,080 --> 00:06:12,070
obviously, but we've kind of
taken things in a very

129
00:06:12,070 --> 00:06:13,320
different direction.

130
00:06:13,320 --> 00:06:16,260

131
00:06:16,260 --> 00:06:20,400
So at a very high level view,
we do look very similar to

132
00:06:20,400 --> 00:06:23,300
some of these other data
parallel runtimes.

133
00:06:23,300 --> 00:06:24,995
We write performance
critical kernels

134
00:06:24,995 --> 00:06:28,550
in a C99 based language.

135
00:06:28,550 --> 00:06:31,620
These kernels are distributed
with your application as

136
00:06:31,620 --> 00:06:33,980
architecture independent
bit code.

137
00:06:33,980 --> 00:06:38,110
We then JIT compile those at
run time to one or more

138
00:06:38,110 --> 00:06:39,680
processor targets.

139
00:06:39,680 --> 00:06:45,490
For example, we may compile them
to ARM D7A with Neon, and

140
00:06:45,490 --> 00:06:49,820
we may compile them to, for
example on the Nexus 10, we

141
00:06:49,820 --> 00:06:52,470
have GPU support in
the Mali-T604.

142
00:06:52,470 --> 00:06:57,010
So we may compile to build a
CPU and GPU at run time.

143
00:06:57,010 --> 00:07:02,720
We also reflect Java classes
for easy integration with

144
00:07:02,720 --> 00:07:03,800
existing applications.

145
00:07:03,800 --> 00:07:05,900
And what this means is
essentially that every time

146
00:07:05,900 --> 00:07:10,180
you have a RenderScript file,
we generate a set of Java

147
00:07:10,180 --> 00:07:14,340
classes that go with it, so that
you can control execution

148
00:07:14,340 --> 00:07:17,740
of that without relying on
string based APIs, or having

149
00:07:17,740 --> 00:07:20,520
to use JNI, or something
like that.

150
00:07:20,520 --> 00:07:23,000
We also have kind of standard
resource management and

151
00:07:23,000 --> 00:07:25,510
execution in our Java
API as well.

152
00:07:25,510 --> 00:07:27,120
One thing I didn't mention
here is we also have a

153
00:07:27,120 --> 00:07:30,330
collection of, they're called
script intrinsics.

154
00:07:30,330 --> 00:07:35,720
Essentially these are built in,
very fast operations that

155
00:07:35,720 --> 00:07:39,860
we can tune to specific
architectures very well.

156
00:07:39,860 --> 00:07:43,830
And they're things like YUV
conversion, or convolution,

157
00:07:43,830 --> 00:07:44,930
stuff like that.

158
00:07:44,930 --> 00:07:49,950
Common operations you may use
very often, where you can get

159
00:07:49,950 --> 00:07:53,590
a really significant speedup by
tuning very, very closely

160
00:07:53,590 --> 00:07:55,180
to a particular piece
of hardware.

161
00:07:55,180 --> 00:07:58,560

162
00:07:58,560 --> 00:08:01,720
So let's go through some basic
RenderScript definitions.

163
00:08:01,720 --> 00:08:04,830
The first thing to talk
about is the element.

164
00:08:04,830 --> 00:08:08,100
So an element is essentially
a C type.

165
00:08:08,100 --> 00:08:10,610
In this case, it's an INT.

166
00:08:10,610 --> 00:08:12,650
So it can be a scalar type,
like an INT, it could be a

167
00:08:12,650 --> 00:08:16,050
vector type, like an INT4,
Float 4, whatever.

168
00:08:16,050 --> 00:08:19,300
We can also supports C
structs as elements.

169
00:08:19,300 --> 00:08:22,850
So if you declare a struct in
your RenderScript file, we

170
00:08:22,850 --> 00:08:27,710
will actually reflect an element
class for that, that

171
00:08:27,710 --> 00:08:29,350
will be available to Java.

172
00:08:29,350 --> 00:08:33,570
So you can use that from
your Java API directly.

173
00:08:33,570 --> 00:08:36,429
So an element is not very
useful in and of itself.

174
00:08:36,429 --> 00:08:39,740
So to actually make use of this,
we have allocations.

175
00:08:39,740 --> 00:08:42,700
And allocations are collections
of a single type

176
00:08:42,700 --> 00:08:47,130
of element in some
arrangement.

177
00:08:47,130 --> 00:08:49,060
It could be 1D or 2D.

178
00:08:49,060 --> 00:08:52,000
They have an x and y dimension,
and they have a

179
00:08:52,000 --> 00:08:52,640
backing store.

180
00:08:52,640 --> 00:08:56,550
And essentially, an allocation
is how you get data from Java

181
00:08:56,550 --> 00:08:58,500
into RenderScript, so
it can be processed

182
00:08:58,500 --> 00:09:02,900
by one or more kernels.

183
00:09:02,900 --> 00:09:06,320
And an allocation has one other
important aspects, and

184
00:09:06,320 --> 00:09:08,480
that is the type.

185
00:09:08,480 --> 00:09:12,500
And the type is essentially the
size of the allocation,

186
00:09:12,500 --> 00:09:17,500
along with the elements used
within that allocation.

187
00:09:17,500 --> 00:09:19,150
And we use this for
two things.

188
00:09:19,150 --> 00:09:25,440
First of all, we use it to do
safety checking on copies and

189
00:09:25,440 --> 00:09:28,050
kernel launches, and things like
that, to make sure that

190
00:09:28,050 --> 00:09:34,170
you don't try to copy an
allocation of floats onto an

191
00:09:34,170 --> 00:09:37,260
allocation of chars, because
it won't fit.

192
00:09:37,260 --> 00:09:43,710
Or a 5x5 allocation of INTs onto
a 3x3 allocation of INTs,

193
00:09:43,710 --> 00:09:45,245
because it won't fit.

194
00:09:45,245 --> 00:09:49,770
We also do type checking when
we launch kernels, to make

195
00:09:49,770 --> 00:09:52,550
sure that the element type
past tense of the kernel

196
00:09:52,550 --> 00:09:55,230
matches what the
kernel expects.

197
00:09:55,230 --> 00:09:58,780
The other way we use types is
to control how much parallel

198
00:09:58,780 --> 00:10:01,440
work actually gets launched
by a kernel.

199
00:10:01,440 --> 00:10:03,504
And we'll get into this
more in a bit.

200
00:10:03,504 --> 00:10:06,280

201
00:10:06,280 --> 00:10:10,300
So this is a dot RS file, a
very basic dot RS file.

202
00:10:10,300 --> 00:10:13,450
And in general, we refer to each
one of these dot RS files

203
00:10:13,450 --> 00:10:14,690
as a script.

204
00:10:14,690 --> 00:10:16,990
And a script is essentially
its own little world.

205
00:10:16,990 --> 00:10:18,930
There's no linkage between
scripts, or

206
00:10:18,930 --> 00:10:20,960
anything like that.

207
00:10:20,960 --> 00:10:23,790
So every script is
self-contained.

208
00:10:23,790 --> 00:10:26,150
And the first thing you'll
notice here is that the script

209
00:10:26,150 --> 00:10:27,970
starts with two pragmas.

210
00:10:27,970 --> 00:10:31,030
First we have the RS
language revision.

211
00:10:31,030 --> 00:10:32,020
For now it's one.

212
00:10:32,020 --> 00:10:34,550
It will be one for the
foreseeable future.

213
00:10:34,550 --> 00:10:38,140
After that, we have a
Java package name.

214
00:10:38,140 --> 00:10:41,410
And this is the package name
that we use for the reflected

215
00:10:41,410 --> 00:10:44,040
classes from this script.

216
00:10:44,040 --> 00:10:47,890
After that we have what looks
like a normal C99 global.

217
00:10:47,890 --> 00:10:49,610
We call that a script
global because it is

218
00:10:49,610 --> 00:10:51,380
local to the script.

219
00:10:51,380 --> 00:10:55,230
And this will reflect a method
called set add val, which

220
00:10:55,230 --> 00:10:57,090
takes an INT to Java.

221
00:10:57,090 --> 00:11:01,360
So if you want to update this
add val global from Java, you

222
00:11:01,360 --> 00:11:03,310
can do that.

223
00:11:03,310 --> 00:11:07,770
After that we have a kernel, and
this kernel looks mostly

224
00:11:07,770 --> 00:11:11,350
like a standard C99 function,
except it has this decorator

225
00:11:11,350 --> 00:11:12,760
attribute kernel.

226
00:11:12,760 --> 00:11:16,400
An attribute kernel is the new
kernel syntax we introduced in

227
00:11:16,400 --> 00:11:19,560
API 17, and I highly recommend
you use that.

228
00:11:19,560 --> 00:11:22,990
And essentially what this means
is the kernel has an

229
00:11:22,990 --> 00:11:25,040
input value and an output.

230
00:11:25,040 --> 00:11:27,260
Or an input type and
an output type.

231
00:11:27,260 --> 00:11:32,470
And here the input type is an
INT, so we get an INT in.

232
00:11:32,470 --> 00:11:37,650
And then we also get two UINT
32Ts, x and y, which are

233
00:11:37,650 --> 00:11:40,050
coordinates within
the allocation.

234
00:11:40,050 --> 00:11:43,410
And this function returns an
INT, so essentially what

235
00:11:43,410 --> 00:11:48,430
happens is when we run this
kernel on a given allocation,

236
00:11:48,430 --> 00:11:52,400
for every element in the
allocation, this function will

237
00:11:52,400 --> 00:11:53,370
be executed.

238
00:11:53,370 --> 00:11:59,180
And so at every particular
coordinate pair in the

239
00:11:59,180 --> 00:12:03,980
allocation, the value of that
element at that location will

240
00:12:03,980 --> 00:12:05,490
be passed to this function.

241
00:12:05,490 --> 00:12:08,040
And then the return value from
this function will be written

242
00:12:08,040 --> 00:12:10,310
to the output application.

243
00:12:10,310 --> 00:12:15,560
So because this kernel has both
an in argument and a non

244
00:12:15,560 --> 00:12:19,040
void return type, it reflects
a method called for each

245
00:12:19,040 --> 00:12:20,630
underscore kernel.

246
00:12:20,630 --> 00:12:22,090
Just kernel here because that's

247
00:12:22,090 --> 00:12:23,620
the name of the function.

248
00:12:23,620 --> 00:12:28,250
And for each kernel takes two
allocations, an input

249
00:12:28,250 --> 00:12:30,380
allocation and an output
application.

250
00:12:30,380 --> 00:12:35,640
If you didn't have INT in and
you simply had x and y, it

251
00:12:35,640 --> 00:12:37,130
would only take the
output allocation.

252
00:12:37,130 --> 00:12:41,480
And similarly, if it didn't
return an INT, but simply

253
00:12:41,480 --> 00:12:44,285
returned void, it would not
need an output allocation.

254
00:12:44,285 --> 00:12:48,960

255
00:12:48,960 --> 00:12:53,450
So I want to talk a little bit
about a more complicated part

256
00:12:53,450 --> 00:12:57,600
of the API where you can do
more advanced things.

257
00:12:57,600 --> 00:12:59,430
And that is called
us script group.

258
00:12:59,430 --> 00:13:02,000
And a script group allows
a group of kernels to be

259
00:13:02,000 --> 00:13:05,580
executed as a single
Java call.

260
00:13:05,580 --> 00:13:08,570
More specifically, this allows
a dag of kernels to be

261
00:13:08,570 --> 00:13:11,110
executed as a single
function call.

262
00:13:11,110 --> 00:13:17,060
And by passing this entire
workload to the driver as one

263
00:13:17,060 --> 00:13:20,890
monolithic entity before we
actually run any part of that

264
00:13:20,890 --> 00:13:24,000
workload, we can enable
all sorts of different

265
00:13:24,000 --> 00:13:28,560
optimizations in the run time,
and in the compiler.

266
00:13:28,560 --> 00:13:31,120
For example, we can actually
enable, like, parallel

267
00:13:31,120 --> 00:13:34,450
execution across devices, or
tiling, kernel fusion, which

268
00:13:34,450 --> 00:13:36,630
we'll get into in a minute.

269
00:13:36,630 --> 00:13:40,200
We actually see some significant
speed improvements

270
00:13:40,200 --> 00:13:42,250
today by using script
group versus

271
00:13:42,250 --> 00:13:44,310
using individual scripts.

272
00:13:44,310 --> 00:13:47,720
And in general, I highly
recommend that you see script

273
00:13:47,720 --> 00:13:50,110
group as much as possible going
forward, because it is a

274
00:13:50,110 --> 00:13:52,040
place where we're going
to spend a lot of time

275
00:13:52,040 --> 00:13:54,130
optimizing.

276
00:13:54,130 --> 00:13:56,750
So let's go through an example
of script group.

277
00:13:56,750 --> 00:14:01,210
So here we have five kernels,
and essentially input is

278
00:14:01,210 --> 00:14:06,330
passed to A, and output comes
from E. And then you have this

279
00:14:06,330 --> 00:14:08,520
set of dependencies
in between.

280
00:14:08,520 --> 00:14:12,330
And according to the semantics
of script group, the

281
00:14:12,330 --> 00:14:15,000
intermediate state is not
visible to the user.

282
00:14:15,000 --> 00:14:19,990
So all of these connections
between A and B and A and C,

283
00:14:19,990 --> 00:14:22,960
et cetera, which would
normally be stored in

284
00:14:22,960 --> 00:14:27,290
programmer managed allocations
are instead simply set up as

285
00:14:27,290 --> 00:14:32,230
connections between these
kernels and the graph.

286
00:14:32,230 --> 00:14:35,790
And what this allows us to do
is the runtime can either

287
00:14:35,790 --> 00:14:39,410
create those allocations if
necessary automatically, or we

288
00:14:39,410 --> 00:14:43,180
can optimize them away
if possible.

289
00:14:43,180 --> 00:14:47,080
And so we can do things here
like, because there's no

290
00:14:47,080 --> 00:14:51,400
dependence between B and C, we
could run B on the CPU and C

291
00:14:51,400 --> 00:14:54,800
on the GPU if possible, or
something like that.

292
00:14:54,800 --> 00:14:57,360
If we wanted to get more
advanced, if we have more

293
00:14:57,360 --> 00:15:00,440
knowledge about the way the
kernels actually run and the

294
00:15:00,440 --> 00:15:04,840
particular dependency
information between colonels,

295
00:15:04,840 --> 00:15:09,540
we could potentially do
something like fusing B and D

296
00:15:09,540 --> 00:15:11,010
into a single kernel.

297
00:15:11,010 --> 00:15:14,550
And this way you could simply
take the results of some

298
00:15:14,550 --> 00:15:18,073
portion of B, depending on how
much you actually need to run

299
00:15:18,073 --> 00:15:22,340
at a time, and immediately start
running that on D. And

300
00:15:22,340 --> 00:15:25,680
this is potentially really good
for GPUs, and also really

301
00:15:25,680 --> 00:15:29,740
good for CPUs, because it allows
you to use things like

302
00:15:29,740 --> 00:15:34,170
local memory on the
GPU, and keep your

303
00:15:34,170 --> 00:15:35,420
cache hot on the CPU.

304
00:15:35,420 --> 00:15:39,580

305
00:15:39,580 --> 00:15:43,860
So I'm going to talk about some
features coming up in an

306
00:15:43,860 --> 00:15:46,560
upcoming release.

307
00:15:46,560 --> 00:15:50,230
And the first feature we will
talk about this is the

308
00:15:50,230 --> 00:15:52,460
compatibility library
for gingerbread.

309
00:15:52,460 --> 00:15:56,020
And I'll go into that in a lot
more detail in a minute.

310
00:15:56,020 --> 00:15:58,860
Other than that, we've added
rsSetElementAt, which

311
00:15:58,860 --> 00:16:01,780
essentially is scatter support
for RenderScript.

312
00:16:01,780 --> 00:16:05,380
You can now write arbitrary
allocations

313
00:16:05,380 --> 00:16:06,960
from a given kernel.

314
00:16:06,960 --> 00:16:09,650
We have debug runtime, which
does things like bounce

315
00:16:09,650 --> 00:16:12,540
checking and prints out errors
to make it easier

316
00:16:12,540 --> 00:16:14,360
to debug your code.

317
00:16:14,360 --> 00:16:17,040
We've added more script
intrinsics, things like 3D

318
00:16:17,040 --> 00:16:21,920
look up tables, and I think
something else.

319
00:16:21,920 --> 00:16:24,990
We have native support for YUV
allocations, so you can take a

320
00:16:24,990 --> 00:16:28,610
YUV allocation directly from a
camera, and process that in

321
00:16:28,610 --> 00:16:29,840
RenderScript.

322
00:16:29,840 --> 00:16:31,720
We've also improved launch
latency significantly.

323
00:16:31,720 --> 00:16:34,820

324
00:16:34,820 --> 00:16:36,700
So, the compatibility library.

325
00:16:36,700 --> 00:16:41,740
The compatibility library
enables API 18 RenderScript on

326
00:16:41,740 --> 00:16:44,280
devices running Gingerbread
or higher.

327
00:16:44,280 --> 00:16:48,570
And the way this works is
essentially we can do an

328
00:16:48,570 --> 00:16:53,880
offline compilation of your
RenderScript bit code.

329
00:16:53,880 --> 00:16:57,180
When you build your app, you can
actually create a shared

330
00:16:57,180 --> 00:16:59,400
library that runs on the CPU.

331
00:16:59,400 --> 00:17:01,570
And we compile this for sort
of the lowest common

332
00:17:01,570 --> 00:17:04,300
denominator CPU that can
run all the way back to

333
00:17:04,300 --> 00:17:05,550
Gingerbread.

334
00:17:05,550 --> 00:17:08,470

335
00:17:08,470 --> 00:17:12,819
When the app is actually built,
then, the compatibility

336
00:17:12,819 --> 00:17:15,630
library, as well as the shared
libraries for your

337
00:17:15,630 --> 00:17:18,619
RenderScript kernels are
packaged with the app.

338
00:17:18,619 --> 00:17:24,369
And we also package the normal
RS bit code as well.

339
00:17:24,369 --> 00:17:28,329
So on an older device, something
running between

340
00:17:28,329 --> 00:17:34,680
Gingerbread and Android 4.2, we
can use this shared library

341
00:17:34,680 --> 00:17:40,080
that we've built into the app
because it doesn't have API18.

342
00:17:40,080 --> 00:17:43,920
On a suitable device, we can
compile the native bit code

343
00:17:43,920 --> 00:17:48,960
automatically and use whatever
processors or optimizations

344
00:17:48,960 --> 00:17:52,370
are available on that device
without the developer having

345
00:17:52,370 --> 00:17:54,050
to do anything special there.

346
00:17:54,050 --> 00:17:56,190
So what this means, essentially,
is that you can

347
00:17:56,190 --> 00:18:02,690
have one APK that runs on the
Nexus 1 running gingerbread.

348
00:18:02,690 --> 00:18:06,900
And you can take that same APK
and run it on the Nexus 10.

349
00:18:06,900 --> 00:18:09,980
And on the Nexus 1, it'll run
using the CPU shared library.

350
00:18:09,980 --> 00:18:15,130
It will run the CPU, and run
as fast as possible there.

351
00:18:15,130 --> 00:18:20,360
And on the Nexus 10, we'll
compile the bit code for A15.

352
00:18:20,360 --> 00:18:23,106
Use whatever A15 optimizations
we can.

353
00:18:23,106 --> 00:18:26,840
We'll use the GPU, and it'll
run a lot faster.

354
00:18:26,840 --> 00:18:28,890
And so now for the first
time, you can do all

355
00:18:28,890 --> 00:18:31,760
that from one APK.

356
00:18:31,760 --> 00:18:35,450
And with that, I'm going to turn
it over to Jason Sams,

357
00:18:35,450 --> 00:18:37,575
who's going to go through
application.

358
00:18:37,575 --> 00:18:43,230

359
00:18:43,230 --> 00:18:44,930
JASON SAMS: Thanks, Tim.

360
00:18:44,930 --> 00:18:46,250
My name is Jason Sams.

361
00:18:46,250 --> 00:18:48,930
I'm the tech lead for
RenderScript script on

362
00:18:48,930 --> 00:18:53,360
Android, and I'm going to take
us through a simple example of

363
00:18:53,360 --> 00:18:55,020
using RenderScript.

364
00:18:55,020 --> 00:18:56,890
And then we're actually going
to follow up with a more

365
00:18:56,890 --> 00:18:58,140
complex example.

366
00:18:58,140 --> 00:19:00,640

367
00:19:00,640 --> 00:19:03,620
So, the examples we're going
to use are going to be a

368
00:19:03,620 --> 00:19:07,420
Gaussian Blur and a histogram.

369
00:19:07,420 --> 00:19:10,700
So for anyone who attended the
talk yesterday that Rowan and

370
00:19:10,700 --> 00:19:12,850
Chet gave, you may have noticed
that they were talking

371
00:19:12,850 --> 00:19:16,070
about doing drop shadows
using RenderScript.

372
00:19:16,070 --> 00:19:18,610
And I'm actually going to talk
about the primitive they're

373
00:19:18,610 --> 00:19:21,280
using to do this.

374
00:19:21,280 --> 00:19:23,390
RenderScript has been optimized
for doing image

375
00:19:23,390 --> 00:19:24,720
processing tasks.

376
00:19:24,720 --> 00:19:27,490
We've been tuning it for
this workload for a

377
00:19:27,490 --> 00:19:28,210
couple years now.

378
00:19:28,210 --> 00:19:31,550
It's getting pretty
good at it.

379
00:19:31,550 --> 00:19:34,730
The intrinsics that Tim
talked about include a

380
00:19:34,730 --> 00:19:36,060
Gaussian Blur intrinsic.

381
00:19:36,060 --> 00:19:41,360
And so for blurring images
or applying other simple

382
00:19:41,360 --> 00:19:45,400
operations to bitmaps, it's
actually extremely easy to do

383
00:19:45,400 --> 00:19:48,850
that, and that's why we'll walk
through that example.

384
00:19:48,850 --> 00:19:51,170
Histogram will demonstrate
some of the more advanced

385
00:19:51,170 --> 00:19:52,730
techniques.

386
00:19:52,730 --> 00:19:55,020
Things I clipped kernel
launches, which

387
00:19:55,020 --> 00:19:57,220
is coming up soon.

388
00:19:57,220 --> 00:20:00,420
The rsSetElementAt, which
Tim was talking about.

389
00:20:00,420 --> 00:20:02,900
And we'll also demonstrate
multipass

390
00:20:02,900 --> 00:20:06,230
processing over a workload.

391
00:20:06,230 --> 00:20:08,870

392
00:20:08,870 --> 00:20:13,270
So general image processing in
RS, and how you go about it.

393
00:20:13,270 --> 00:20:18,010
The code to do this is actually
pretty simple, and

394
00:20:18,010 --> 00:20:19,980
the first thing you'll want to
do in an application, if

395
00:20:19,980 --> 00:20:23,320
you're going to do some use of
RS is you'll want to create a

396
00:20:23,320 --> 00:20:25,310
RenderScript context.

397
00:20:25,310 --> 00:20:30,090
And the first line of our code,
we create this context.

398
00:20:30,090 --> 00:20:34,500
We actually pass the application
context to that.

399
00:20:34,500 --> 00:20:36,950
Now, coming up soon we'll
actually have a few additional

400
00:20:36,950 --> 00:20:40,860
flags you can pass here, one
of which is a debug mode,

401
00:20:40,860 --> 00:20:43,690
which you can pass into your
contacts creation, and it'll

402
00:20:43,690 --> 00:20:46,590
do things like range check
your access and give you

403
00:20:46,590 --> 00:20:50,210
additional warnings, or errors
if it detects something that's

404
00:20:50,210 --> 00:20:53,070
not optimal, or wrong.

405
00:20:53,070 --> 00:20:56,310
But the next step you'll want
to do is actually create one

406
00:20:56,310 --> 00:20:58,270
of those RenderScript
allocations.

407
00:20:58,270 --> 00:21:00,850
And typically if you're doing
image processing, your input's

408
00:21:00,850 --> 00:21:02,760
probably going to be
a bitmap. map.

409
00:21:02,760 --> 00:21:06,540
And so we have a create from
bitmap helper function, which

410
00:21:06,540 --> 00:21:09,580
will actually create an
allocation from a bitmap, and

411
00:21:09,580 --> 00:21:12,650
it'll automatically set the type
and the height and the

412
00:21:12,650 --> 00:21:16,680
width of that allocation to that
of the incoming bitmap.

413
00:21:16,680 --> 00:21:19,140
Now in addition, you can
optionally map that

414
00:21:19,140 --> 00:21:23,610
allocation, and we have
a few usage flags.

415
00:21:23,610 --> 00:21:27,650
Usage shared, it's new,
or upcoming soon.

416
00:21:27,650 --> 00:21:30,350
And it allows us to share the
back end store with the

417
00:21:30,350 --> 00:21:33,230
bitmap, and that avoids a lot of
the copy overhead that you

418
00:21:33,230 --> 00:21:37,020
would normally get if you had
a separate bitmap and

419
00:21:37,020 --> 00:21:40,870
allocation in the older APIs.

420
00:21:40,870 --> 00:21:42,260
Also, usage graphic texture.

421
00:21:42,260 --> 00:21:44,820
If you were going to use this
in combination with RS

422
00:21:44,820 --> 00:21:47,790
sampler, you can set the
flag to enable that.

423
00:21:47,790 --> 00:21:49,240
And usage script just
means we're going to

424
00:21:49,240 --> 00:21:50,720
pass it into a kernel.

425
00:21:50,720 --> 00:21:52,650
Now, this is actually the
default set of flags, so if

426
00:21:52,650 --> 00:21:54,380
you were to weed the flags
off completely, this is

427
00:21:54,380 --> 00:21:56,130
what you would get.

428
00:21:56,130 --> 00:21:58,460
For the output, we're going
to write this to a bitmap.

429
00:21:58,460 --> 00:22:01,260
So we'll create a second
allocation, and I'm going to

430
00:22:01,260 --> 00:22:04,170
leave off the graphics texture
usage, because we're not going

431
00:22:04,170 --> 00:22:07,440
to sample from it.

432
00:22:07,440 --> 00:22:10,150
So we have a bitmap we're going
to work on, and we're

433
00:22:10,150 --> 00:22:14,070
going to apply a large
blur to this.

434
00:22:14,070 --> 00:22:16,910
So after you have your two
allocations, how would you go

435
00:22:16,910 --> 00:22:19,180
about blurring that image?

436
00:22:19,180 --> 00:22:21,900
The first thing I would do is
I would create a variable to

437
00:22:21,900 --> 00:22:25,750
hold the intrinsic script,
that is the blur.

438
00:22:25,750 --> 00:22:29,130
And then I would create
that blur script.

439
00:22:29,130 --> 00:22:31,360
In this case, since it's an
intrinsic, you don't actually

440
00:22:31,360 --> 00:22:32,760
have to provide a dot RS file.

441
00:22:32,760 --> 00:22:35,530
It's built into the system, But
You still need to tell it

442
00:22:35,530 --> 00:22:38,170
what type of data you
want it to work on.

443
00:22:38,170 --> 00:22:41,340
In this case, we're going
to say it's a uchar4.

444
00:22:41,340 --> 00:22:44,880
That's the element
U8 underscore 4.

445
00:22:44,880 --> 00:22:48,340
We support just uchar buffers,
if you had, say, an alpha

446
00:22:48,340 --> 00:22:51,880
channel, or just a
grayscale image.

447
00:22:51,880 --> 00:22:55,060
And now we'll take that script
that we loaded, and we'll

448
00:22:55,060 --> 00:22:57,230
configure it to perform
our blur.

449
00:22:57,230 --> 00:22:58,810
Now, I'm going to first
set of radius.

450
00:22:58,810 --> 00:22:59,775
In this case, we're
going to set it to

451
00:22:59,775 --> 00:23:01,220
a nice, large radius.

452
00:23:01,220 --> 00:23:05,410
20 pixels, so it's going to
be a big blur operation.

453
00:23:05,410 --> 00:23:08,190
And we'll set on that script
the input allocation we

454
00:23:08,190 --> 00:23:12,260
created in the previous slide,
that will act as our input.

455
00:23:12,260 --> 00:23:14,490
And for the blur, we're
going to run it.

456
00:23:14,490 --> 00:23:16,160
We're just going to call
it the for each.

457
00:23:16,160 --> 00:23:19,510
Since it's an intrinsic, there
is actually no name provided.

458
00:23:19,510 --> 00:23:22,720
It's just called for each, and
write it to our output

459
00:23:22,720 --> 00:23:24,300
allocation.

460
00:23:24,300 --> 00:23:28,850
And after we have done that,
we need to copy our output

461
00:23:28,850 --> 00:23:31,520
allocation back into
our output bitmap.

462
00:23:31,520 --> 00:23:34,400
Now, with usage shared it's
possible this will be a no op

463
00:23:34,400 --> 00:23:36,553
on some devices, and be
extremely efficient.

464
00:23:36,553 --> 00:23:39,460

465
00:23:39,460 --> 00:23:42,880
And with that, you get
a nice blurred image.

466
00:23:42,880 --> 00:23:45,780
This intrinsic is actually
implemented extremely

467
00:23:45,780 --> 00:23:46,970
efficiently.

468
00:23:46,970 --> 00:23:49,620
So if you have an ARM device,
you get handed to a Neon.

469
00:23:49,620 --> 00:23:51,960
If you have an x86 device,
you get SSE that's been

470
00:23:51,960 --> 00:23:53,670
hand-tuned.

471
00:23:53,670 --> 00:23:57,030
On some devices you'll get
a hand-tuned GPU kernel.

472
00:23:57,030 --> 00:23:59,450
So it really is up to each
device how they implement

473
00:23:59,450 --> 00:24:02,660
this, but the key takeaway is
on each device, it's pretty

474
00:24:02,660 --> 00:24:04,050
much the fastest
possible way to

475
00:24:04,050 --> 00:24:05,410
implement it on that device.

476
00:24:05,410 --> 00:24:08,260

477
00:24:08,260 --> 00:24:09,790
Now for histogram, this
is going to be a

478
00:24:09,790 --> 00:24:11,850
more complex example.

479
00:24:11,850 --> 00:24:14,600
We're going to present an
algorithm that does the

480
00:24:14,600 --> 00:24:16,840
histogram in two passes.

481
00:24:16,840 --> 00:24:20,100
The first pass we'll use a
large number of workers.

482
00:24:20,100 --> 00:24:24,540
The second pass will be a much
smaller summation pass.

483
00:24:24,540 --> 00:24:28,180
We do this because the first
pass, we're breaking the image

484
00:24:28,180 --> 00:24:32,540
up into chunks to build
intermediate sums.

485
00:24:32,540 --> 00:24:36,550
And that allows us to do a
lot of work in parallel.

486
00:24:36,550 --> 00:24:39,290
And we'll for the purpose of
time ignore the actual

487
00:24:39,290 --> 00:24:42,170
rendering pass into how we draw
it on the screen, because

488
00:24:42,170 --> 00:24:43,790
there's a lot of different ways
you could theoretically

489
00:24:43,790 --> 00:24:46,790
render this.

490
00:24:46,790 --> 00:24:49,550
So how would you write
a histogram script?

491
00:24:49,550 --> 00:24:51,480
Now, since we don't have an
intrinsic, I'm actually going

492
00:24:51,480 --> 00:24:53,760
to write a dot RS file.

493
00:24:53,760 --> 00:24:56,670
The first thing I'm going to
do is declare some globals.

494
00:24:56,670 --> 00:24:58,060
In this case they're
going to be an RS

495
00:24:58,060 --> 00:24:59,800
underscore allocation type.

496
00:24:59,800 --> 00:25:02,350
That is just the script
equivalent of the allocation

497
00:25:02,350 --> 00:25:05,850
class on the Java side
that will hold our

498
00:25:05,850 --> 00:25:08,710
input and output data.

499
00:25:08,710 --> 00:25:11,840
I will also attach, since it's
a multipass, an intermediate

500
00:25:11,840 --> 00:25:16,130
buffer that'll hold the sums
from the first pass.

501
00:25:16,130 --> 00:25:20,020
And that buffer will be the
number of steps, meaning how

502
00:25:20,020 --> 00:25:23,640
many threads I'm going to run to
do the summations, and 256

503
00:25:23,640 --> 00:25:26,685
units wide, one for each
level of the histogram.

504
00:25:26,685 --> 00:25:29,290

505
00:25:29,290 --> 00:25:32,130
And we'll also have a final sum
buffer, which will just be

506
00:25:32,130 --> 00:25:39,200
a one dimensional allocation
of 256 different levels.

507
00:25:39,200 --> 00:25:42,460
So, additional globals we're
going to pass in will have

508
00:25:42,460 --> 00:25:45,450
just integers that will
represent the height and width

509
00:25:45,450 --> 00:25:48,230
of the input image.

510
00:25:48,230 --> 00:25:51,650
And we will have an integer
which will represent how many

511
00:25:51,650 --> 00:25:55,740
steps, or how many items is in
each step of the image, and

512
00:25:55,740 --> 00:25:56,990
how many steps are in total.

513
00:25:56,990 --> 00:26:00,140

514
00:26:00,140 --> 00:26:03,400
So the kernel for the first
pass, and I'll have a diagram

515
00:26:03,400 --> 00:26:05,950
of how this works in a moment.

516
00:26:05,950 --> 00:26:08,720
What this is going to do is
it's going to walk over a

517
00:26:08,720 --> 00:26:13,070
number of scan lines
in the image.

518
00:26:13,070 --> 00:26:14,750
However many scan lines
will be determined

519
00:26:14,750 --> 00:26:16,430
by the steps value.

520
00:26:16,430 --> 00:26:19,750
Typically you're going to see
values like two or four.

521
00:26:19,750 --> 00:26:21,930
I tried experimentally, a number
of different steps

522
00:26:21,930 --> 00:26:23,940
value, and it's very hardware
dependent what the most

523
00:26:23,940 --> 00:26:26,550
efficient value is.

524
00:26:26,550 --> 00:26:28,930
But you can actually pick values
that worked across a

525
00:26:28,930 --> 00:26:32,160
very large range of hardware.

526
00:26:32,160 --> 00:26:35,190
And we're going to actually
run this kernel.

527
00:26:35,190 --> 00:26:37,200
So you see it takes an x and
y-coordinate, because it's

528
00:26:37,200 --> 00:26:39,500
running on a 2D input image.

529
00:26:39,500 --> 00:26:42,050
But when we watch the kernel
from the Java side, we're

530
00:26:42,050 --> 00:26:44,440
actually going to clip it so
that it only iterates over x

531
00:26:44,440 --> 00:26:47,110
equals 0 and walks through the
different y-coordinates.

532
00:26:47,110 --> 00:26:49,610
I'll go over how we
do that in a bit.

533
00:26:49,610 --> 00:26:53,290
So the first thing we do for
each of these histogram worker

534
00:26:53,290 --> 00:26:55,000
threads is we're going to want
to clear our output of

535
00:26:55,000 --> 00:26:56,460
accumulation buffers.

536
00:26:56,460 --> 00:27:00,490
And I do that just by walking
through a simple loop that

537
00:27:00,490 --> 00:27:02,670
sets the sums buffer.

538
00:27:02,670 --> 00:27:05,600
It sets our particular line, and
then we just loop over the

539
00:27:05,600 --> 00:27:10,200
256 elements.

540
00:27:10,200 --> 00:27:12,990
So, continuing our first pass.

541
00:27:12,990 --> 00:27:15,610
After we've cleared our
accumulation buffer, we'll

542
00:27:15,610 --> 00:27:18,930
need to iterate over
our image.

543
00:27:18,930 --> 00:27:22,810
And we do this for 0 to
the number of scan

544
00:27:22,810 --> 00:27:24,575
lines in our step.

545
00:27:24,575 --> 00:27:27,230
Then we calculate which
wine we're working on.

546
00:27:27,230 --> 00:27:29,220
That's the PY variable.

547
00:27:29,220 --> 00:27:34,140
And if steps is not equally
divisible by the number of

548
00:27:34,140 --> 00:27:36,610
lines in the image, it's
possible we'll need to check

549
00:27:36,610 --> 00:27:37,700
for an overrun here.

550
00:27:37,700 --> 00:27:41,900
So we'll return in that case,
because we'll be done.

551
00:27:41,900 --> 00:27:44,750
And then we walk through
one scan line.

552
00:27:44,750 --> 00:27:49,350
So we just iterate in the kernel
from left to right, and

553
00:27:49,350 --> 00:27:53,670
we'll get an element from our
input image and load that into

554
00:27:53,670 --> 00:27:56,550
a temporary uchar4 value.

555
00:27:56,550 --> 00:28:00,050
We then calculate a luminance
value from that.

556
00:28:00,050 --> 00:28:02,590
In this case, it's just
the integer math.

557
00:28:02,590 --> 00:28:05,820
Nothing terribly exciting.

558
00:28:05,820 --> 00:28:08,980
And then after we've calculated
a luminance value,

559
00:28:08,980 --> 00:28:13,590
we use that is the x-coordinate
index into our

560
00:28:13,590 --> 00:28:17,290
intermediate buffer, and we
load the existing value,

561
00:28:17,290 --> 00:28:19,850
increment it by one, and then
you set [INAUDIBLE]

562
00:28:19,850 --> 00:28:21,350
to write it back.

563
00:28:21,350 --> 00:28:24,360
And this is how we're constantly
accumulating from

564
00:28:24,360 --> 00:28:26,530
each work item and
output value.

565
00:28:26,530 --> 00:28:29,750

566
00:28:29,750 --> 00:28:34,310
So for the second pass, after
the first pass, we have

567
00:28:34,310 --> 00:28:39,220
basically an image which a
number of temporary buffers

568
00:28:39,220 --> 00:28:44,000
that indicate however many
values of each level were run

569
00:28:44,000 --> 00:28:45,340
for that threat.

570
00:28:45,340 --> 00:28:47,810
Now we need to sum all those
together and get one set of

571
00:28:47,810 --> 00:28:51,190
results, not n sets
of results.

572
00:28:51,190 --> 00:28:54,890
This kernel is a 1D kernel, so
it's only going to operate

573
00:28:54,890 --> 00:28:57,400
over one dimension.

574
00:28:57,400 --> 00:29:02,510
And we just simply loop over
within that kernel the input

575
00:29:02,510 --> 00:29:06,930
values, and sum up one vertical
column of levels.

576
00:29:06,930 --> 00:29:11,100
And we return the sum, and that
writes the output value

577
00:29:11,100 --> 00:29:12,350
for that level.

578
00:29:12,350 --> 00:29:15,390

579
00:29:15,390 --> 00:29:18,050
So, rescale.

580
00:29:18,050 --> 00:29:20,590
This is an example of an
invokable function.

581
00:29:20,590 --> 00:29:26,410
So after we have our buffer that
has 256 items and tells

582
00:29:26,410 --> 00:29:30,350
you how many pixels of each
level it saw, what you may

583
00:29:30,350 --> 00:29:33,750
want to do is actually rescale
that to some range.

584
00:29:33,750 --> 00:29:35,770
In this case we'll have
an invokable.

585
00:29:35,770 --> 00:29:38,400
If you notice, there's no
decoration kernel on this.

586
00:29:38,400 --> 00:29:42,130
And it's going to be called
single threaded.

587
00:29:42,130 --> 00:29:44,290
This is good for very small
workloads where you don't want

588
00:29:44,290 --> 00:29:47,230
to necessarily launch a lot
of threads and do a lot of

589
00:29:47,230 --> 00:29:50,560
overhead for a very small
amount of work.

590
00:29:50,560 --> 00:29:54,780
So we loop over, we find the
maximum value in terms of any

591
00:29:54,780 --> 00:29:58,430
one bucket, and then we just
integrate over our buckets,

592
00:29:58,430 --> 00:30:03,520
and we divide the values there
by the greatest value to

593
00:30:03,520 --> 00:30:05,060
effectively normalize
the range.

594
00:30:05,060 --> 00:30:08,890

595
00:30:08,890 --> 00:30:11,160
So what does this look like
on the Java side?

596
00:30:11,160 --> 00:30:13,440
So you've written this
dot RS file.

597
00:30:13,440 --> 00:30:15,450
What do you actually do with
it in terms of interfacing

598
00:30:15,450 --> 00:30:17,870
that with your application?

599
00:30:17,870 --> 00:30:20,720
Well, the first thing you
need to do is load it.

600
00:30:20,720 --> 00:30:23,560
The first line here
is how we do that.

601
00:30:23,560 --> 00:30:26,440
We create a script variable, and
then we can just say new

602
00:30:26,440 --> 00:30:28,510
script C underscore whatever
the name of

603
00:30:28,510 --> 00:30:30,540
your dot RS file is.

604
00:30:30,540 --> 00:30:33,840
And this works because we've
reflected a Java file from

605
00:30:33,840 --> 00:30:36,620
your dot RS file, and
effectively you now have a

606
00:30:36,620 --> 00:30:41,180
Java class with all the methods
that you could use to

607
00:30:41,180 --> 00:30:44,870
actually talk to that
dot RS file.

608
00:30:44,870 --> 00:30:48,090
And so after it's loaded, things
like the width and the

609
00:30:48,090 --> 00:30:51,500
height, those globals, you can
just actually call Java

610
00:30:51,500 --> 00:30:53,545
methods, and it will
set those for you.

611
00:30:53,545 --> 00:30:57,070
You can set any value you want
at that point, but in this

612
00:30:57,070 --> 00:30:59,830
case we'll set the width.

613
00:30:59,830 --> 00:31:00,010
Now

614
00:31:00,010 --> 00:31:03,430
We, need to create the
allocations to hold our data.

615
00:31:03,430 --> 00:31:05,770
We demonstrated earlier how you
would create the input and

616
00:31:05,770 --> 00:31:08,840
output allocations for the
input image and the final

617
00:31:08,840 --> 00:31:12,420
image, but how do you create
those intermediate buffers?

618
00:31:12,420 --> 00:31:14,790
In this case, we're going to
have to do it by building a

619
00:31:14,790 --> 00:31:18,620
custom type, because it's
going to be shaped very

620
00:31:18,620 --> 00:31:21,800
specific to that intermediate
buffer.

621
00:31:21,800 --> 00:31:23,250
So we create a type builder.

622
00:31:23,250 --> 00:31:27,320
We specify an element of INT
32, which is just regular

623
00:31:27,320 --> 00:31:30,030
integer is our element type.

624
00:31:30,030 --> 00:31:33,490
And then we set the x and y
dimensions that we want, in

625
00:31:33,490 --> 00:31:37,560
this case, 256 wide
by steps high.

626
00:31:37,560 --> 00:31:39,230
We create a type from that.

627
00:31:39,230 --> 00:31:42,310
That's the dimensions
of the allocation.

628
00:31:42,310 --> 00:31:46,850
And then we actually allocate
the back end store from that.

629
00:31:46,850 --> 00:31:50,220
So we'll also need to create
that 1D buffer to hold the

630
00:31:50,220 --> 00:31:52,840
final histogram.

631
00:31:52,840 --> 00:31:55,310
And in this case, we'll
again choose INT.

632
00:31:55,310 --> 00:31:57,540
But we have a helper function so
that you don't necessarily

633
00:31:57,540 --> 00:32:00,020
have to create a type for every

634
00:32:00,020 --> 00:32:02,040
allocation you want to create.

635
00:32:02,040 --> 00:32:04,750
If it's a 1D allocation, we
actually have a helper

636
00:32:04,750 --> 00:32:06,450
function that will automatically
create

637
00:32:06,450 --> 00:32:08,210
a 1D type for you.

638
00:32:08,210 --> 00:32:11,720
In this case, 256 elements.

639
00:32:11,720 --> 00:32:14,960
And then we set those
allocations we just created to

640
00:32:14,960 --> 00:32:17,910
the script.

641
00:32:17,910 --> 00:32:21,100
So, running the first pass.

642
00:32:21,100 --> 00:32:25,590
Now, launching scripts from
Java, very straightforward.

643
00:32:25,590 --> 00:32:27,030
But we're going to do something
a little more

644
00:32:27,030 --> 00:32:30,120
complicated than we talked
about in the blur.

645
00:32:30,120 --> 00:32:32,360
If you remember when we talked
about the first paths, we said

646
00:32:32,360 --> 00:32:34,950
we're going to clip this kernel
so that it only ran on

647
00:32:34,950 --> 00:32:39,610
x equals zero, but actually
iterated over all the y's.

648
00:32:39,610 --> 00:32:43,270
So coming soon we have on the
Java side, a new option for

649
00:32:43,270 --> 00:32:46,300
launching kernels, and the
ability to clip the kernel to

650
00:32:46,300 --> 00:32:48,950
the region of interest
that you want that

651
00:32:48,950 --> 00:32:49,580
kernel to run on.

652
00:32:49,580 --> 00:32:53,020
This is very useful if you want
to either do what I'm

653
00:32:53,020 --> 00:32:57,320
about to do here, or if you're
just editing part of an image.

654
00:32:57,320 --> 00:33:00,430
We create a launch option
structure, and then

655
00:33:00,430 --> 00:33:01,700
we set the x range.

656
00:33:01,700 --> 00:33:04,080
The first value's inclusive, the
second value's exclusive,

657
00:33:04,080 --> 00:33:06,200
so that's why you see 0 to 1.

658
00:33:06,200 --> 00:33:10,120
And then we do our for each
pass, and coming soon, not

659
00:33:10,120 --> 00:33:13,220
only can you specify the input
or output allocation, but we

660
00:33:13,220 --> 00:33:15,700
actually reflect overloaded
versions of this that will

661
00:33:15,700 --> 00:33:21,560
take the launch options,
if you so choose.

662
00:33:21,560 --> 00:33:24,450
And so what does this actually
look like running?

663
00:33:24,450 --> 00:33:27,030
So we have the allocation
we created.

664
00:33:27,030 --> 00:33:28,820
The kernel's going
to an each time C

665
00:33:28,820 --> 00:33:30,410
x-coordinate equals zero.

666
00:33:30,410 --> 00:33:32,950
And it's going to see a
y-coordinate that is the

667
00:33:32,950 --> 00:33:35,920
number of steps, as
we drew earlier.

668
00:33:35,920 --> 00:33:40,430

669
00:33:40,430 --> 00:33:41,830
Now, running the second pass.

670
00:33:41,830 --> 00:33:46,050
So after you run the first pass,
the output will be in

671
00:33:46,050 --> 00:33:48,210
that intermediate buffer.

672
00:33:48,210 --> 00:33:52,160
And you can just immediately
call the for each on pass two,

673
00:33:52,160 --> 00:33:55,200
and this will sum the first
buffer into the second, and

674
00:33:55,200 --> 00:33:58,670
now you have a single
allocation, which contains

675
00:33:58,670 --> 00:34:00,680
your range of values.

676
00:34:00,680 --> 00:34:04,350
And we can simply call
re-scale by invoke.

677
00:34:04,350 --> 00:34:05,520
If you notice, this
doesn't take any

678
00:34:05,520 --> 00:34:07,320
parameters in this example.

679
00:34:07,320 --> 00:34:10,610
Invoke functions are actually
very useful for

680
00:34:10,610 --> 00:34:12,370
things like set up.

681
00:34:12,370 --> 00:34:16,150
So if in the dot RS file, you
put some parameters in the

682
00:34:16,150 --> 00:34:19,150
prototype for that function,
you can actually pass them

683
00:34:19,150 --> 00:34:20,469
directly here.

684
00:34:20,469 --> 00:34:21,969
However, you cannot
return values.

685
00:34:21,969 --> 00:34:25,719
So the prototype always
must be void.

686
00:34:25,719 --> 00:34:28,969
And you have your histogram.

687
00:34:28,969 --> 00:34:32,219
So with that, I'm going to open
it up to questions, if

688
00:34:32,219 --> 00:34:33,469
Tim would join us again.

689
00:34:33,469 --> 00:34:36,179

690
00:34:36,179 --> 00:34:37,429
Thanks, everyone.

691
00:34:37,429 --> 00:34:44,159

692
00:34:44,159 --> 00:34:46,620
One other comment, during office
hours I actually have

693
00:34:46,620 --> 00:34:51,440
both an ARM and x86 device that
can be seen running this

694
00:34:51,440 --> 00:34:53,790
example, if anyone's curious.

695
00:34:53,790 --> 00:34:57,240
But it runs very well
on both devices.

696
00:34:57,240 --> 00:35:01,730
The good news here is by writing
in the agnostic code,

697
00:35:01,730 --> 00:35:04,640
we actually generate back end
code that is optimal for all.

698
00:35:04,640 --> 00:35:10,220

699
00:35:10,220 --> 00:35:11,095
Hello.

700
00:35:11,095 --> 00:35:13,740
Take the first question?

701
00:35:13,740 --> 00:35:15,020
AUDIENCE: So you had mentioned
two things.

702
00:35:15,020 --> 00:35:18,230
You mentioned that the ISP and
DSPs, so that's the mobile

703
00:35:18,230 --> 00:35:22,480
devices, is there any access to
the fixed function hardware

704
00:35:22,480 --> 00:35:25,730
like the fast resizing, the fast
color space conversion

705
00:35:25,730 --> 00:35:27,210
you see on ISPs?

706
00:35:27,210 --> 00:35:30,850
And then my second question
was are there any plans to

707
00:35:30,850 --> 00:35:34,150
have RenderScript run on
something other than Android?

708
00:35:34,150 --> 00:35:38,830
Even if it's Chromebooks, or
just regular old Linux.

709
00:35:38,830 --> 00:35:40,970
JASON SAMS: OK, I'll go ahead
and answer the first one.

710
00:35:40,970 --> 00:35:42,620
The answer is yes.

711
00:35:42,620 --> 00:35:46,970
Part of the reason we have
intrinsics is we can use

712
00:35:46,970 --> 00:35:50,730
processors that are more fixed
function than you can by

713
00:35:50,730 --> 00:35:53,930
writing code directly from
a dot RS, or dot FS file.

714
00:35:53,930 --> 00:35:55,990
And so something like the
Gaussian Blur we used as an

715
00:35:55,990 --> 00:35:58,090
example, we actually have other
intrinsics like involved

716
00:35:58,090 --> 00:36:02,450
3x3 and 5x5, those will run very
well on something like a

717
00:36:02,450 --> 00:36:04,510
fixed function ISP or DSP.

718
00:36:04,510 --> 00:36:07,850
Another example that's our YUV
to RGB conversion, again, you

719
00:36:07,850 --> 00:36:09,140
should be able to take advantage
of that fixed

720
00:36:09,140 --> 00:36:10,490
function hardware, because
it's going to be both

721
00:36:10,490 --> 00:36:15,120
extremely power efficient,
and usually very fast.

722
00:36:15,120 --> 00:36:16,210
I'll let you take
the second one.

723
00:36:16,210 --> 00:36:19,660
TIM MURRAY: So as far as other
platforms, it's possible.

724
00:36:19,660 --> 00:36:24,600
Basically during my spare time
in the last six months or so,

725
00:36:24,600 --> 00:36:29,980
I ported this two CUBE
standard Linux.

726
00:36:29,980 --> 00:36:32,940
It just runs on the CPU, but it
was really straightforward,

727
00:36:32,940 --> 00:36:37,710
because we make such heavy use
of LLVM and Clang, essentially

728
00:36:37,710 --> 00:36:41,477
we can port trivially to any
platform that has an LLVM and

729
00:36:41,477 --> 00:36:44,410
Clang, good LLVM and
CLang support.

730
00:36:44,410 --> 00:36:47,220
So in an upcoming AOSP release,
you'll see all sorts

731
00:36:47,220 --> 00:36:51,020
of ifdefs for things
like RS server.

732
00:36:51,020 --> 00:36:53,800
And if you wanted to construct
your own MIG file with an

733
00:36:53,800 --> 00:36:55,520
appropriate version of LLVM
and Clang, you could

734
00:36:55,520 --> 00:36:57,240
certainly do that.

735
00:36:57,240 --> 00:36:59,200
AUDIENCE: Thanks.

736
00:36:59,200 --> 00:36:59,925
AUDIENCE: Hi.

737
00:36:59,925 --> 00:37:04,500
I was wondering when the API
18 RenderScript stuff gets

738
00:37:04,500 --> 00:37:05,700
into the compatibility
package.

739
00:37:05,700 --> 00:37:08,060
Will that include the
script intrinsics?

740
00:37:08,060 --> 00:37:09,183
JASON SAMS: Yes.

741
00:37:09,183 --> 00:37:09,556
AUDIENCE: OK.

742
00:37:09,556 --> 00:37:10,420
Easy question.

743
00:37:10,420 --> 00:37:12,120
Oh, follow up.

744
00:37:12,120 --> 00:37:13,510
Is there any time
frame for that?

745
00:37:13,510 --> 00:37:13,765
JASON SAMS: No.

746
00:37:13,765 --> 00:37:16,210
TIM MURRAY: No.

747
00:37:16,210 --> 00:37:18,260
JASON SAMS: You can't
trick us.

748
00:37:18,260 --> 00:37:21,470
AUDIENCE: So just to confirm,
the Gingerbread stuff is

749
00:37:21,470 --> 00:37:23,530
dependent upon 18 coming out.

750
00:37:23,530 --> 00:37:24,412
And then the compatibility
library

751
00:37:24,412 --> 00:37:26,100
will have that, correct?

752
00:37:26,100 --> 00:37:26,860
TIM MURRAY: Correct.

753
00:37:26,860 --> 00:37:29,360
AUDIENCE: OK, follow up is what
memory constraints are

754
00:37:29,360 --> 00:37:32,400
there for the size of the
RenderScript kernels

755
00:37:32,400 --> 00:37:34,340
that you can build?

756
00:37:34,340 --> 00:37:37,280
TIM MURRAY: What do you
mean by the size?

757
00:37:37,280 --> 00:37:41,900
AUDIENCE: Byte code size, like
how big of function or sets of

758
00:37:41,900 --> 00:37:45,895
functions can you build for
might be hitting memory issues

759
00:37:45,895 --> 00:37:48,326
in your device dependent,
or things that you

760
00:37:48,326 --> 00:37:49,670
have seen in the wild?

761
00:37:49,670 --> 00:37:52,500
JASON SAMS: I've seen an entire
H264 encoder written in

762
00:37:52,500 --> 00:37:56,240
RenderScript, so the size
limits are pretty high.

763
00:37:56,240 --> 00:37:57,770
TIM MURRAY: Yeah, I don't think
you'll run into too many

764
00:37:57,770 --> 00:37:59,100
issues with code size.

765
00:37:59,100 --> 00:38:01,610

766
00:38:01,610 --> 00:38:02,790
AUDIENCE: Hi, my name is Mark.

767
00:38:02,790 --> 00:38:05,460
I would like to know, like, more
from the graphical side

768
00:38:05,460 --> 00:38:10,070
of Android, so they are really
high, dedicated examples of

769
00:38:10,070 --> 00:38:11,520
doing graphics in
Windows script.

770
00:38:11,520 --> 00:38:14,910
Like for example, the page
flipping in the ebook reader,

771
00:38:14,910 --> 00:38:18,960
and in the YouTube app, and I
guess the cover flow and the

772
00:38:18,960 --> 00:38:22,210
play music is also done
with Windows script.

773
00:38:22,210 --> 00:38:25,670
Have you thought of building
a website with really high,

774
00:38:25,670 --> 00:38:27,810
dedicated examples with
Windows script?

775
00:38:27,810 --> 00:38:30,650

776
00:38:30,650 --> 00:38:33,030
TIM MURRAY: So we are trying to
improve our documentation

777
00:38:33,030 --> 00:38:34,850
and improve our samples.

778
00:38:34,850 --> 00:38:39,720
In API [INAUDIBLE] you'll see
a lot of new and kind of

779
00:38:39,720 --> 00:38:42,030
hopefully clearer
documentation.

780
00:38:42,030 --> 00:38:45,150
Samples we are working on, in
general, one of hte best

781
00:38:45,150 --> 00:38:48,420
places to look right now, we
have a test called image

782
00:38:48,420 --> 00:38:50,050
processing.

783
00:38:50,050 --> 00:38:51,660
You can find that in ALSP.

784
00:38:51,660 --> 00:38:54,460
That has a lot of different
kernels, and can basically

785
00:38:54,460 --> 00:38:56,840
give you a good idea of how
to write a RenderScript

786
00:38:56,840 --> 00:38:58,250
application.

787
00:38:58,250 --> 00:39:01,150
AUDIENCE: So, no website
available with great examples

788
00:39:01,150 --> 00:39:04,342
here, just the examples
in the SDK?

789
00:39:04,342 --> 00:39:05,480
TIM MURRAY: Yeah, most likely.

790
00:39:05,480 --> 00:39:09,390
I mean, that's where we're
focusing for now.

791
00:39:09,390 --> 00:39:12,560
AUDIENCE: You said you're not
going to support anything

792
00:39:12,560 --> 00:39:14,663
other than the CPU
on Gingerbread.

793
00:39:14,663 --> 00:39:17,026
Is there a technical reason
you can't do that?

794
00:39:17,026 --> 00:39:19,440
I mean, there are a lot
of usable phone DSPs.

795
00:39:19,440 --> 00:39:21,060
TIM MURRAY: Yeah, so essentially
we would need a

796
00:39:21,060 --> 00:39:28,700
new driver on there, and the way
we have our driver work is

797
00:39:28,700 --> 00:39:30,340
we're an OS component.

798
00:39:30,340 --> 00:39:33,090
And the way we can get around
that on the compatibility

799
00:39:33,090 --> 00:39:37,790
library is by loading these
shared libraries, which,

800
00:39:37,790 --> 00:39:39,390
they're not OS components.

801
00:39:39,390 --> 00:39:42,640
So essentially, if we were to
try to support anything more

802
00:39:42,640 --> 00:39:47,130
than the CPU on Gingerbread,
they would have to update that

803
00:39:47,130 --> 00:39:49,290
part of their OS.

804
00:39:49,290 --> 00:39:51,390
AUDIENCE: So is there no way to
get access to, say, like,

805
00:39:51,390 --> 00:39:53,160
TIDSP or anything like that?

806
00:39:53,160 --> 00:39:54,375
TIM MURRAY: Not on
Gingerbread, no.

807
00:39:54,375 --> 00:39:56,250
JASON SAMS: The support
necessarily in the OS simply

808
00:39:56,250 --> 00:39:59,020
wasn't there in Gingerbread, so
there's really nothing we

809
00:39:59,020 --> 00:40:02,020
can do without an OS update.

810
00:40:02,020 --> 00:40:02,760
OK, thanks everyone.

811
00:40:02,760 --> 00:40:05,600
I think we're out of time, so
will be around for office

812
00:40:05,600 --> 00:40:07,310
hours if anyone has additional
questions.

813
00:40:07,310 --> 00:40:11,043

